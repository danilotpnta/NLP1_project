{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-aRiOgl4nHg"
      },
      "source": [
        "------\n",
        "**You cannot save any changes you make to this file, so please make sure to save it on your Google Colab drive or download it as a .ipynb file.**\n",
        "\n",
        "------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIZrAUx57vsM"
      },
      "source": [
        "Practical 1: Sentiment Detection in Movie Reviews\n",
        "========================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4kXPMhyngZW"
      },
      "source": [
        "This practical concerns detecting sentiment in movie reviews. This is a typical NLP classification task.\n",
        "In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n",
        "Each review is a **document** and consists of one or more sentences.\n",
        "\n",
        "To prepare yourself for this practical, you should\n",
        "have a look at a few of these texts to understand the difficulties of\n",
        "the task: how might one go about classifying the texts? You will write\n",
        "code that decides whether a movie review conveys positive or\n",
        "negative sentiment.\n",
        "\n",
        "Please make sure you have read the following paper:\n",
        "\n",
        ">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n",
        "(2002).\n",
        "[Thumbs up? Sentiment Classification using Machine Learning\n",
        "Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n",
        "\n",
        "Bo Pang et al. introduced the movie review sentiment\n",
        "classification task, and the above paper was one of the first papers on\n",
        "the topic. The first version of your sentiment classifier will do\n",
        "something similar to Pang et al.'s system. If you have questions about it,\n",
        "you should resolve you doubts as soon as possible with your TA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7errgRASzZ"
      },
      "source": [
        "**Advice**\n",
        "\n",
        "Please read through the entire practical and familiarise\n",
        "yourself with all requirements before you start coding or otherwise\n",
        "solving the tasks. Writing clean and concise code can make the difference\n",
        "between solving the assignment in a matter of hours, and taking days to\n",
        "run all experiments.\n",
        "\n",
        "\n",
        "**Implementation**\n",
        "\n",
        "While we inserted code cells to indicate where you should implement your own code, please feel free to add/remove code blocks where you see fit (but make sure that the general structure of the assignment is preserved). Also, please keep in mind that it is always good practice to structure your code properly, e.g., by implementing separate classes and functions that can be reused.\n",
        "\n",
        "## Environment\n",
        "\n",
        "All code should be written in **Python 3**.\n",
        "This is the default in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaZnxptMJiD7",
        "outputId": "5be587dc-934b-4600-ef54-495e7c125190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYZyIF7lJnGn"
      },
      "source": [
        "If you want to run code on your own computer, then download this notebook through `File -> Download .ipynb`.\n",
        "The easiest way to\n",
        "install Python is through downloading\n",
        "[Anaconda](https://www.anaconda.com/download).\n",
        "After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n",
        "You can also use an IDE\n",
        "such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n",
        "coding and debugging easier. It is good practice to create a [virtual\n",
        "environment](https://docs.python.org/3/tutorial/venv.html) for this\n",
        "project, so that any Python packages don’t interfere with other\n",
        "projects.\n",
        "\n",
        "\n",
        "**Learning Python 3**\n",
        "\n",
        "If you are new to Python 3, you may want to check out a few of these resources:\n",
        "- https://learnxinyminutes.com/docs/python3/\n",
        "- https://www.learnpython.org/\n",
        "- https://docs.python.org/3/tutorial/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hok-BFu9lGoK"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "from subprocess import call\n",
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import sklearn as sk\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import json\n",
        "from collections import Counter\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXWyGHwE-ieQ"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "**Download the sentiment lexicon and the movie reviews dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm-rakqtlMOT",
        "outputId": "60f857c1-540a-4875-e072-6cd4b71c59b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-09 10:24:10--  https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662577 (647K) [text/plain]\n",
            "Saving to: ‘sent_lexicon.2’\n",
            "\n",
            "sent_lexicon.2      100%[===================>] 647.05K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-11-09 10:24:10 (11.9 MB/s) - ‘sent_lexicon.2’ saved [662577/662577]\n",
            "\n",
            "--2023-11-09 10:24:10--  https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83503869 (80M) [text/plain]\n",
            "Saving to: ‘reviews.json.2’\n",
            "\n",
            "reviews.json.2      100%[===================>]  79.63M   254MB/s    in 0.3s    \n",
            "\n",
            "2023-11-09 10:24:10 (254 MB/s) - ‘reviews.json.2’ saved [83503869/83503869]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download sentiment lexicon\n",
        "!wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
        "# download review data\n",
        "!wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkPwuHp5LSuQ"
      },
      "source": [
        "**Load the movie reviews.**\n",
        "\n",
        "Each word in a review comes with its part-of-speech tag. For documentation on POS-tags, see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "careEKj-mRpl",
        "outputId": "0c279d7c-f037-4637-cc80-2c6db4b9deda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of reviews: 2000 \n",
            "\n",
            "0 NEG 29\n",
            "Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n",
            "1 NEG 11\n",
            "Damn/JJ that/IN Y2K/CD bug/NN ./.\n",
            "2 NEG 24\n",
            "It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n",
            "3 NEG 19\n",
            "QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n",
            "4 NEG 38\n",
            "Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n",
            "\n",
            "Number of word types: 47743\n",
            "Number of word tokens: 1512359\n",
            "\n",
            "Most common tokens:\n",
            "         , :    77842\n",
            "       the :    75948\n",
            "         . :    59027\n",
            "         a :    37583\n",
            "       and :    35235\n",
            "        of :    33864\n",
            "        to :    31601\n",
            "        is :    25972\n",
            "        in :    21563\n",
            "        's :    18043\n",
            "        it :    15904\n",
            "      that :    15820\n",
            "     -rrb- :    11768\n",
            "     -lrb- :    11670\n",
            "        as :    11312\n",
            "      with :    10739\n",
            "       for :     9816\n",
            "       his :     9542\n",
            "      this :     9497\n",
            "      film :     9404\n"
          ]
        }
      ],
      "source": [
        "# file structure:\n",
        "# [\n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list}\n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list}\n",
        "#   ..\n",
        "# ]\n",
        "# where `content` is a list of sentences,\n",
        "# with a sentence being a list of (token, pos_tag) pairs.\n",
        "\n",
        "\n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  reviews = json.load(f)\n",
        "\n",
        "print(\"Total number of reviews:\", len(reviews), '\\n')\n",
        "\n",
        "def print_sentence_with_pos(s):\n",
        "  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n",
        "\n",
        "for i, r in enumerate(reviews):\n",
        "  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n",
        "  print_sentence_with_pos(r[\"content\"][0])\n",
        "  if i == 4:\n",
        "    break\n",
        "\n",
        "c = Counter()\n",
        "for review in reviews:\n",
        "  for sentence in review[\"content\"]:\n",
        "    for token, pos_tag in sentence:\n",
        "      c[token.lower()] += 1\n",
        "\n",
        "print(\"\\nNumber of word types:\", len(c))\n",
        "print(\"Number of word tokens:\", sum(c.values()))\n",
        "\n",
        "print(\"\\nMost common tokens:\")\n",
        "for token, count in c.most_common(20):\n",
        "  print(\"%10s : %8d\" % (token, count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6PWaEoh8B34"
      },
      "source": [
        "#(1) Lexicon-based approach (3.5pts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsTSMb6ma4E8"
      },
      "source": [
        "A traditional approach to classify documents according to their sentiment is the lexicon-based approach. To implement this approach, you need a **sentiment lexicon**, i.e., a list of words annotated with a sentiment label (e.g., positive and negative, or a score from 0 to 5).\n",
        "\n",
        "In this practical, you will use the sentiment\n",
        "lexicon released by Wilson et al. (2005).\n",
        "\n",
        "> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n",
        "(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n",
        "Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP.\n",
        "\n",
        "Pay attention to all the information available in the sentiment lexicon. The field *word1* contains the lemma, *priorpolarity* contains the sentiment label (positive, negative, both, or neutral), *type* gives you the magnitude of the word's sentiment (strong or weak), and *pos1* gives you the part-of-speech tag of the lemma. Some lemmas can have multiple part-of-speech tags and thus multiple entries in the lexicon. The path of the lexicon file is `\"sent_lexicon\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogq0Eq2hQglh",
        "outputId": "2226ecbb-e0df-4bb9-9ff2-1829aa8c6803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative\n",
            "type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative\n",
            "type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative\n",
            "type=strongsubj len=1 word1=abase pos1=verb stemmed1=y priorpolarity=negative\n",
            "type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y priorpolarity=negative\n"
          ]
        }
      ],
      "source": [
        "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  line_cnt = 0\n",
        "  for line in f:\n",
        "    print(line.strip())\n",
        "    line_cnt += 1\n",
        "    if line_cnt > 4:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mml4nOtIUBhn"
      },
      "source": [
        "Lexica such as this can be used to solve\n",
        "the classification task without using Machine Learning. For example, one might look up every word $w_1 ... w_n$ in a document, and compute a **binary score**\n",
        "$S_{binary}$ by counting how many words have a positive or a\n",
        "negative label in the sentiment lexicon $SLex$.\n",
        "\n",
        "$$S_{binary}(w_1 w_2 ... w_n) = \\sum_{i = 1}^{n}\\text{sign}(SLex\\big[w_i\\big])$$\n",
        "\n",
        "where $\\text{sign}(SLex\\big[w_i\\big])$ refers to the polarity of $w_i$.\n",
        "\n",
        "**Threshold.** On average, there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n",
        "\n",
        "$$\n",
        "\\text{classify}(S_{binary}(w_1 w_2 ... w_n)) = \\bigg\\{\\begin{array}{ll}\n",
        "        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n",
        "        \\text{negative} & \\text{otherwise}\n",
        "        \\end{array}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOFnMvbeeZrc"
      },
      "source": [
        "#### (Q1.1) Implement this approach and report its classification accuracy. (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1ZQrjKs4ksg"
      },
      "outputs": [],
      "source": [
        "def make_lexicon(weighted=False):\n",
        "    \"\"\"\n",
        "    Create a lexicon from a file containing sentiment data.\n",
        "\n",
        "    This function reads a text file named \"sent_lexicon\" and extracts word-sentiment pairs to create a lexicon\n",
        "    that associates words with their corresponding sentiments. Optionally, it can include word magnitudes in the lexicon if\n",
        "    the 'weighted' parameter is set to True.\n",
        "\n",
        "    Parameters:\n",
        "    weighted (bool, optional): If True, include word magnitudes along with sentiments in the lexicon.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words, and values are sentiment labels (e.g., 'positive', 'negative').\n",
        "    If 'weighted' is True, the values are lists containing magnitude and sentiment, e.g., ['magnitude', 'positive'].\n",
        "\n",
        "    Example:\n",
        "    If \"sent_lexicon\" contains the following lines:\n",
        "    \"type=weak word=amazing sentiment=positive\"\n",
        "    \"type=strong word=terrible sentiment=negative\"\n",
        "\n",
        "    If 'weighted' is set to False, the resulting lexicon will be:\n",
        "    {\n",
        "        \"amazing\": \"positive\",\n",
        "        \"terrible\": \"negative\"\n",
        "    }\n",
        "\n",
        "    If 'weighted' is set to True, the resulting lexicon will be:\n",
        "    {\n",
        "        \"amazing\": ['weaksubj', \"positive\"],\n",
        "        \"terrible\": ['strongsubj', \"negative\"]\n",
        "    }\n",
        "    \"\"\"\n",
        "    lexicon = {}\n",
        "    with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "      for line in f:\n",
        "          parts = line.strip().split()\n",
        "          magnitude = parts[0].split('=')[1]\n",
        "          word = parts[2].split('=')[1]\n",
        "          sentiment = parts[5].split('=')[1]\n",
        "\n",
        "          if weighted:\n",
        "            lexicon[word] = [magnitude, sentiment]\n",
        "          else:\n",
        "            lexicon[word] = sentiment\n",
        "      return lexicon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED2aTEYutW1-"
      },
      "outputs": [],
      "source": [
        "def classify_review(review, lexicon, weighted=False, threshold=8):\n",
        "    \"\"\"\n",
        "    Classify a review as positive or negative based on a lexicon.\n",
        "\n",
        "    This function takes a review as input and classifies it as 'POS' (positive) or 'NEG' (negative) based on the provided lexicon.\n",
        "    Optionally, it supports weighting the sentiment based on a magnitude factor and a specified ratio for the binary score threshold.\n",
        "\n",
        "    Parameters:\n",
        "    review (str): The input review to be classified.\n",
        "    lexicon (dict): A dictionary where keys are words, and values are sentiment labels, including optional magnitude information.\n",
        "    weighted (bool, optional): If True, the sentiment scoring considers the magnitude of subjectivity (default: False).\n",
        "    ratio (float, optional): A positive real number to adjust the binary score threshold (default: 1).\n",
        "\n",
        "    Returns:\n",
        "    str: 'POS' if the review is classified as positive, 'NEG' otherwise.\n",
        "\n",
        "    The function tokenizes the input review into words and calculates a binary score based on the lexicon. If 'weighted' is True, the sentiment scoring also considers the magnitude factor. The final classification is based on comparing the binary score to a threshold defined by the 'ratio' parameter.\n",
        "    \"\"\"\n",
        "    # Tokenize the document into words\n",
        "    words = review.split()\n",
        "    sbinary = 0\n",
        "    # Calculate the binary score based on the lexicon\n",
        "    for word in words:\n",
        "      if weighted is False:\n",
        "        sentiment = lexicon.get(word)\n",
        "        if sentiment == \"positive\":\n",
        "          sbinary += 1\n",
        "        elif sentiment == \"negative\":\n",
        "          sbinary -= 1\n",
        "      else:\n",
        "        sentiment = lexicon.get(word)[1] if lexicon.get(word) is not None else None\n",
        "        magnitude = lexicon.get(word)[0] if lexicon.get(word) is not None else None\n",
        "        if sentiment == \"positive\":\n",
        "          sbinary += 1 if magnitude == \"weaksubj\" else 2 if magnitude == \"strongsubj\" else 0\n",
        "        elif sentiment == \"negative\":\n",
        "          sbinary -= 1 if magnitude == \"weaksubj\" else 2 if magnitude == \"strongsubj\" else 0\n",
        "\n",
        "    if sbinary > threshold:\n",
        "        return 'POS'\n",
        "    else:\n",
        "        return 'NEG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd7M8nh874F0"
      },
      "outputs": [],
      "source": [
        "def full_sentence(s):\n",
        "    \"\"\"\n",
        "    Construct a full sentence from a list of tokens.\n",
        "\n",
        "    This function takes a list of tokens, where each token is represented as a tuple (token, pos_tag), and constructs a full\n",
        "    sentence by joining the tokens with spaces.\n",
        "\n",
        "    Parameters:\n",
        "    s (list): A list of tokens, where each token is a tuple (token, pos_tag), and the second element of the tuple is ignored.\n",
        "\n",
        "    Returns:\n",
        "    str: A string representing the full sentence constructed by joining the tokens with spaces.\n",
        "    \"\"\"\n",
        "    return \" \".join(\"%s\" % token for token, _ in s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlneI-PEUnZP"
      },
      "outputs": [],
      "source": [
        "def build_document(review):\n",
        "  \"\"\"\n",
        "    Build a document by combining sub-reviews from a review.\n",
        "\n",
        "    This function takes a review, which is typically a dictionary with a \"content\" key containing a list of sub-reviews.\n",
        "    It constructs a single document by joining the sub-reviews with spaces.\n",
        "\n",
        "    Parameters:\n",
        "    review (dict): A dictionary containing sub-reviews under the \"content\" key.\n",
        "\n",
        "    Returns:\n",
        "    str: A string representing the document created by joining the sub-reviews.\n",
        "  \"\"\"\n",
        "  document = [full_sentence(sub_review) for sub_review in review[\"content\"]]\n",
        "  joined_document = ' '.join(document)\n",
        "  return joined_document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy528EUTphz5",
        "outputId": "b81249d7-c9ff-4b9b-c937-0af0a87b956b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.679\n"
          ]
        }
      ],
      "source": [
        "# token_results should be a list of binary indicators; for example [1, 0, 1, ...]\n",
        "# where 1 indicates a correct classification and 0 an incorrect classification.\n",
        "lexicon = make_lexicon(weighted=False)\n",
        "\n",
        "token_results = []\n",
        "\n",
        "for review in reviews:\n",
        "  document = build_document(review) # Combine all the sub-reviews together in a string\n",
        "\n",
        "  true_sentiment = review[\"sentiment\"] # Get true sentiment\n",
        "  predict_sentiment = classify_review(document, lexicon) # Make a prediciton\n",
        "\n",
        "  token_results.append(1 if true_sentiment == predict_sentiment else 0) # If prediction is correct add 1\n",
        "\n",
        "token_accuracy = sum(token_results)/len(token_results)\n",
        "print(\"Accuracy: %0.3f\" % token_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twox0s_3eS0V"
      },
      "source": [
        "As the sentiment lexicon also has information about the **magnitude** of\n",
        "sentiment (e.g., *“excellent\"* has the same sentiment _polarity_ as *“good\"* but it has a higher magnitude), we can take a more fine-grained approach by adding up all\n",
        "sentiment scores, and deciding the polarity of the movie review using\n",
        "the sign of the weighted score $S_{weighted}$.\n",
        "\n",
        "$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n",
        "\n",
        "\n",
        "Make sure you define an appropriate threshold for this approach.\n",
        "\n",
        "#### (Q1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTRNijlqdBXX"
      },
      "outputs": [],
      "source": [
        "def ratio_imbalence(lexicon):\n",
        "  \"\"\"\n",
        "    Calculate the ratio of strong subjective words associated with positive sentiment\n",
        "    to strong subjective words associated with negative sentiment in a sentiment lexicon.\n",
        "\n",
        "    This function takes a sentiment lexicon as input and calculates the ratio of strong subjective words associated\n",
        "    with positive sentiment to strong subjective words associated with negative sentiment.\n",
        "\n",
        "    The idea is the following, since a strong magnitude is twice as important as a weak one, if more of them are positive\n",
        "    then negative (or vice-versa) we want to take this into account by mutiplying this ratio by the threshold.\n",
        "\n",
        "    Parameters:\n",
        "    lexicon (dict): A dictionary where keys are words, and values are sentiment labels.\n",
        "\n",
        "    Returns:\n",
        "    float: The ratio of strong subjective words with positive sentiment to strong subjective words with negative sentiment.\n",
        "  \"\"\"\n",
        "  get_all_values = np.array(list(lexicon.values()))\n",
        "  amount_strong_neg = sum(1 for value in get_all_values if 'strongsubj' in value and 'negative' in value)\n",
        "  amount_strong_pos = sum(1 for value in get_all_values if 'strongsubj' in value and 'positive' in value)\n",
        "  return amount_strong_pos, amount_strong_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vVk7CvDpyka",
        "outputId": "35eaa765-5f71-4df2-dbab-8cc05074821e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total amount of strong positive words 1470\n",
            "The total amount of strong negative words 3061\n",
            "As a result, since there is a 0.48023521724926493 higher positive ratio we can higher the threshold to 9\n",
            "Accuracy: 0.6890\n"
          ]
        }
      ],
      "source": [
        "lexicon = make_lexicon(weighted=True)\n",
        "\n",
        "amount_strong_pos, amount_strong_neg = ratio_imbalence(lexicon)\n",
        "print(\"The total amount of strong positive words\", amount_strong_pos)\n",
        "print(\"The total amount of strong negative words\", amount_strong_neg)\n",
        "print(\"As a result, since there is a\", amount_strong_pos/amount_strong_neg, \"higher positive ratio we can higher the threshold to 9\")\n",
        "magnitude_results = []\n",
        "\n",
        "for review in reviews:\n",
        "  document = build_document(review) # Combine all the sub-reviews together in a string\n",
        "\n",
        "  true_sentiment = review[\"sentiment\"] # Get true sentiment\n",
        "  predict_sentiment = classify_review(document, lexicon, weighted=True, threshold=9)  # Make a prediciton\n",
        "\n",
        "  magnitude_results.append(1 if true_sentiment == predict_sentiment else 0) # If prediction is correct add 1\n",
        "\n",
        "magnitude_accuracy = sum(magnitude_results)/len(magnitude_results)\n",
        "print(\"Accuracy: %0.4f\" % magnitude_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SHoGPfsAHV"
      },
      "source": [
        "#### (Q.1.3) Make a barplot of the two results (0.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8LgBcYcXsEk3",
        "outputId": "32e62c23-f1e7-49cc-83e7-f566e33c4e55"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHWCAYAAABACtmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABS1ElEQVR4nO3deVgVdf//8dcB5aAgi4KASqCYW5q7hOZSYVZmappLC4hpfcvMwjby616SleVdWra5fF3SNDPvFq0bs9zSXFMzF3JXQDRB0UA58/vDH+fuxIHhKHpQn4/rOtfl+ZzPzLznLDO+mJnPWAzDMAQAAAAAKJKHuwsAAAAAgLKO4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4ASgzNm9e7fuvPNO+fv7y2KxaNGiRVe8huXLl8tisWj58uX2tn79+ikyMtKh3+nTpzVgwACFhobKYrHomWeekSSlp6erZ8+eqlKliiwWiyZOnHjFaofrlixZoiZNmsjb21sWi0UnT5686Hk5++5caRaLRaNGjXJo++WXX9S6dWv5+PjIYrFo8+bNGjVqlCwWyxWvb9++fbJYLJo+ffoVX3Zpmj59uiwWi/bt2+fuUq4IZ9tA4HpSzt0FANeq9957T4MGDVKrVq20du1ad5dzVYmPj9fevXv16quvKiAgQC1atHB3SUUaN26cpk+fruHDhysqKkr169eXJD377LNaunSpRo4cqdDQ0DK9Du+9954qVqyofv36mfY9c+aMXn/9dXXo0EEdOnS47LVdCcePH1evXr100003afLkybJarfLx8XF3WaXq3LlzeuCBB+Tt7a23335bFStWVERExGVf7pw5c5SRkWH/gwJKz6hRozR69GgdO3ZMQUFB7i4HuD4YAC6L1q1bG5GRkYYkY/fu3e4u56px5swZQ5IxbNgwt9bxww8/GJKMH374wd6Wl5dn/PXXXw79oqOjjTZt2hSaPiQkxHjooYcud5ml4qabbjLat29for7Hjh0zJBkjR468rDVdSd9++60hyfj+++9LZX7OvjtX2tmzZ41z587Zn+/YscOQZHz00UcO/c6dO2ecPXv2stXRuXNnIyIiolC7zWYzzp49a5w/f/6yLftKOH/+vHH27FnDZrNd8WWPHDnSkGQcO3bsii3T2TYQuJ5wqh5wGezdu1erV6/WW2+9peDgYM2ePdvdJRUpJyfH3SU4OHbsmCQpICCg1OZZWutYvnx5Wa1Wh7aMjAyntRbVfrHOnz+vvLy8Upsf/isjI0NS6X7n3M3b21vlyv33pJKi1rFcuXLy9va+kqVJunAqobe3tzw9Pa/4skuTp6en/fTO64GzbSBwPSE4AZfB7NmzFRgYqM6dO6tnz55FBqeTJ0/q2WefVWRkpKxWq2rUqKG4uDhlZmba+/z1118aNWqU6tSpI29vb4WFhen+++9XamqqpKKvp3B2DUG/fv3k6+ur1NRU3XPPPapUqZIeeughSdKKFSv0wAMP6IYbbpDValV4eLieffZZnT17tlDdv//+u3r16qXg4GBVqFBBdevW1bBhwyRJP/zwgywWi7744otC082ZM0cWi0Vr1qxx+n6MGjXKfvrQ888/L4vF4nA+/aZNm3T33XfLz89Pvr6+uuOOO/Tzzz87zKPgmoMff/xRTz75pKpWraoaNWo4XV6BQ4cOqVu3bvLx8VHVqlX17LPPKjc3t1C/v5/fX/C+7927V19//bUsFov9/bZYLDIMQ5MnT7a3Fzh58qSeeeYZhYeHy2q1qnbt2ho/frxsNpu9T8Fn9+abb2rixImKioqS1WrVb7/9Zn//e/bsqcqVK8vb21stWrTQ4sWLnb4Pq1atUmJiooKDg+Xj46Pu3bvbw6kkRUZGavv27frxxx/ttRZ1Ct6+ffsUHBwsSRo9erS9/6hRozRt2jRZLBZt2rSp0HTjxo2Tp6enDh8+LEnq0KGDGjZsqA0bNqh169aqUKGCatasqSlTphSaNjc3VyNHjlTt2rXt38sXXnjB6efjzPz589W8eXNVqFBBQUFBevjhh+11FNQSHx8vSWrZsqUsFovpKYuHDx/Wo48+qmrVqslqtapmzZp64oknig22Jf19paWlKSEhQTVq1JDValVYWJi6du3qcA3N+vXr1alTJwUFBdnfu/79+zvM5+/XOPXr10/t27eXJD3wwAMOn3FR1zjNmjVLrVq1UsWKFRUYGKh27drpu+++s7/+5ZdfqnPnzvb3ICoqSmPHjlV+fr7De/v1119r//799u9Kwe+nqGucli1bprZt28rHx0cBAQHq2rWrduzY4dCnoOY9e/aoX79+CggIkL+/vxISEnTmzJkiP4MCkZGRTj9jZ6efvvvuu7rpppvs70OLFi00Z84c++vOrnGKjIzUvffeq5UrV6pVq1by9vZWrVq19H//93+Flvnrr7+qffv2qlChgmrUqKFXXnnF/lsqreumzLYXGRkZCg4OVocOHWQYhr19z5498vHxUe/eve1tzq5xstls+te//qVGjRrJ29tbwcHBuuuuu7R+/Xp7n/Pnz2vs2LH2bVlkZKRefvnlQr9jV947wB24xgm4DGbPnq37779fXl5e6tu3r95//3398ssvatmypb3P6dOn1bZtW+3YsUP9+/dXs2bNlJmZqcWLF+vQoUMKCgpSfn6+7r33XqWkpKhPnz4aMmSITp06pe+//17btm1TVFSUy7WdP39enTp10q233qo333xTFStWlHThP5hnzpzRE088oSpVqmjdunV69913dejQIc2fP98+/a+//qq2bduqfPnyeuyxxxQZGanU1FT9+9//1quvvqoOHTooPDxcs2fPVvfu3Qu9L1FRUYqJiXFa2/3336+AgAA9++yz6tu3r+655x75+vpKkrZv3662bdvKz89PL7zwgsqXL68PPvhAHTp00I8//qjo6GiHeT355JMKDg7WiBEjij3idPbsWd1xxx06cOCAnn76aVWrVk0zZ87UsmXLin0f69evr5kzZ+rZZ59VjRo1NHToUElS06ZNNXPmTD3yyCPq2LGj4uLi7NOcOXNG7du31+HDh/X444/rhhtu0OrVq5WUlKSjR48WGkBi2rRp+uuvv/TYY4/JarWqcuXK2r59u9q0aaPq1avrpZdeko+Pjz777DN169ZNn3/+eaH3fPDgwQoMDNTIkSO1b98+TZw4UU899ZTmzZsnSZo4caIGDx4sX19fe/gNCQlxus7BwcF6//339cQTT6h79+66//77JUk333yzatasqUGDBmn27Nlq2rSpw3SzZ89Whw4dVL16dXvbn3/+qXvuuUe9evVS37599dlnn+mJJ56Ql5eXPQTYbDbdd999WrlypR577DHVr19fW7du1dtvv61du3aZDhoyffp0JSQkqGXLlkpOTlZ6err+9a9/adWqVdq0aZMCAgI0bNgw1a1bVx9++KHGjBmjmjVrFvu7OnLkiFq1aqWTJ0/qscceU7169XT48GEtWLBAZ86ckZeXl9PpSvr76tGjh7Zv367BgwcrMjJSGRkZ+v7773XgwAH78zvvvFPBwcF66aWXFBAQoH379mnhwoVF1vz444+revXqGjdunJ5++mm1bNmyyM9YuhCKR40apdatW2vMmDHy8vLS2rVrtWzZMt15553299bX11eJiYny9fXVsmXLNGLECGVnZ+uNN96QJA0bNkxZWVk6dOiQ3n77bUmy/56d+c9//qO7775btWrV0qhRo3T27Fm9++67atOmjTZu3FjoP+y9evVSzZo1lZycrI0bN+rjjz9W1apVNX78+CKX4YqPPvpITz/9tHr27KkhQ4bor7/+0q+//qq1a9fqwQcfLHbaPXv2qGfPnnr00UcVHx+vqVOnql+/fmrevLluuukmSRcC+G233SaLxaKkpCT5+Pjo448/LtUjOiXZXlStWlXvv/++HnjgAb377rt6+umnZbPZ1K9fP1WqVEnvvfdesct49NFHNX36dN19990aMGCAzp8/rxUrVujnn3+2X9s5YMAAzZgxQz179tTQoUO1du1aJScna8eOHYX+yFaS9w5wG3efKwhca9avX+9wvYTNZjNq1KhhDBkyxKHfiBEjDEnGwoULC82j4Hz5qVOnGpKMt956q8g+RV1PsXfvXkOSMW3aNHtbfHy8Icl46aWXCs3vzJkzhdqSk5MNi8Vi7N+/397Wrl07o1KlSg5tf6/HMAwjKSnJsFqtxsmTJ+1tGRkZRrly5UyvjSmo+4033nBo79atm+Hl5WWkpqba244cOWJUqlTJaNeunb1t2rRphiTj1ltvLdH1ExMnTjQkGZ999pm9LScnx6hdu3ah9zU+Pr7Q9RoRERFG586dC81XkjFo0CCHtrFjxxo+Pj7Grl27HNpfeuklw9PT0zhw4IDDe+Dn52dkZGQ49L3jjjuMRo0aOVxnYLPZjNatWxs33nhjofchNjbW4bN59tlnDU9PT4fPprSucerbt69RrVo1Iz8/3962cePGQt/D9u3bG5KMCRMm2Ntyc3ONJk2aGFWrVjXy8vIMwzCMmTNnGh4eHsaKFSscljNlyhRDkrFq1aoi68zLyzOqVq1qNGzY0OEanq+++sqQZIwYMcLeVvBe/fLLL6brHxcXZ3h4eDjtW9xvsiS/rz///NPpd//vvvjiixLV+s/PqKCm+fPnO/QruE6mwO7duw0PDw+je/fuDp/j39evqPV5/PHHjYoVKzp8N4u6xsnZ9qng8z9+/Li9bcuWLYaHh4cRFxdXqOb+/fs7zLN79+5GlSpVCi3rnyIiIoz4+PhC7e3bt3f4HXTt2tW46aabip1XwXdn7969DvOXZPz000/2toyMDMNqtRpDhw61tw0ePNiwWCzGpk2b7G3Hjx83KleuXGiezpTkGqeSbi8M48Lvt2LFisauXbuMN954w5BkLFq0yKHPP7eBy5YtMyQZTz/9dKFlF3xfNm/ebEgyBgwY4PD6c889Z0gyli1bZm8r6XsHuAun6gGlbPbs2QoJCdFtt90m6cIpM71799bcuXMdTmP5/PPP1bhx40JHCAqmKegTFBSkwYMHF9nnYjzxxBOF2ipUqGD/d05OjjIzM9W6dWsZhmE//erYsWP66aef1L9/f91www1F1hMXF6fc3FwtWLDA3jZv3jydP39eDz/8sMv15ufn67vvvlO3bt1Uq1Yte3tYWJgefPBBrVy5UtnZ2Q7TDBw4sETXT3zzzTcKCwtTz5497W0VK1bUY4895nKdZubPn6+2bdsqMDBQmZmZ9kdsbKzy8/P1008/OfTv0aOH/dQ4STpx4oSWLVumXr166dSpU/bpjx8/rk6dOmn37t0Op6FJ0mOPPebw2bRt21b5+fnav39/qa9fXFycjhw5oh9++MHeNnv2bFWoUEE9evRw6FuuXDk9/vjj9udeXl56/PHHlZGRoQ0bNki68H7Vr19f9erVc3i/br/9dklyWM4/rV+/XhkZGXryyScdruHp3Lmz6tWrp6+//trl9bPZbFq0aJG6dOnidJTE4n6TJfl9VahQQV5eXlq+fLn+/PNPp/MpuEbpq6++0rlz51xeBzOLFi2SzWbTiBEj5OHh+F+Ev6/f39en4LvYtm1bnTlzRr///rvLyz169Kg2b96sfv36qXLlyvb2m2++WR07dtQ333xTaJr/+Z//cXjetm1bHT9+vNC24GIFBATo0KFD+uWXX1yetkGDBmrbtq39eXBwsOrWras//vjD3rZkyRLFxMSoSZMm9rbKlSvbT5++VK5uLyZNmiR/f3/17NlTw4cP1yOPPKKuXbsWu4zPP/9cFotFI0eOLPRawfel4LNLTEx0eL3gKP0/f4slee8AdyE4AaUoPz9fc+fO1W233aa9e/dqz5492rNnj6Kjo5Wenq6UlBR739TUVDVs2LDY+aWmpqpu3boOF3lfqnLlyjm95ufAgQP2/7T4+voqODjYfl1EVlaWJNl3XGZ116tXTy1btnS4tmv27Nm65ZZbVLt2bZdrPnbsmM6cOaO6desWeq1+/fqy2Ww6ePCgQ3vNmjVLNO/9+/erdu3ahf7T62xZl2r37t1asmSJgoODHR6xsbGS/nsBf4F/rsOePXtkGIaGDx9eaB4F/3H55zz+GXADAwMlqcj/mF+Kjh07KiwszP6522w2ffrpp+ratasqVark0LdatWqFhvyuU6eOJNmv7di9e7e2b99eaF0L+v1zXf+uIBg6+xzr1at3UcHx2LFjys7ONv3+O1OS35fVatX48eP17bffKiQkRO3atdPrr7+utLQ0+3zat2+vHj16aPTo0QoKClLXrl01bdq0El/zZSY1NVUeHh5q0KBBsf22b9+u7t27y9/fX35+fgoODrb/UaRgfVxR3OdVv359ZWZmFjrl9nJ/t1988UX5+vqqVatWuvHGGzVo0CCtWrWqRNP+s7aC+v5eW8G2558uZhvpjKvbi8qVK+udd97Rr7/+Kn9/f73zzjumy0hNTVW1atUcwu4/7d+/Xx4eHoXWKzQ0VAEBAYV+iyV57wB34RonoBQtW7ZMR48e1dy5czV37txCr8+ePdt+jUBpKeqv3H8/uvV3Vqu10F+S8/Pz1bFjR504cUIvvvii6tWrJx8fHx0+fFj9+vVzGLigpOLi4jRkyBAdOnRIubm5+vnnnzVp0iSX53Ox/v4X8bLCZrOpY8eOeuGFF5y+XhAICvxzHQo+h+eee06dOnVyOo9//uekqKNuxt8uAi8tnp6eevDBB/XRRx/pvffe06pVq3TkyJGLOsooXVjfRo0a6a233nL6enh4+KWUe8W48vt65pln1KVLFy1atEhLly7V8OHDlZycrGXLlqlp06ayWCxasGCBfv75Z/373//W0qVL1b9/f02YMEE///xzsdcQlZaTJ0+qffv28vPz05gxYxQVFSVvb29t3LhRL7744kVtLy7GxX63i9tm/n2e9evX186dO/XVV19pyZIl+vzzz/Xee+9pxIgRGj169GWprTRdzPZi6dKlki6Ez0OHDpXqSJMlPUuiLLx3QFEITkApmj17tqpWrarJkycXem3hwoX64osvNGXKFFWoUEFRUVHatm1bsfOLiorS2rVrde7cOZUvX95pn4K/sp48edKh3ZW/qG/dulW7du3SjBkzHAYz+P777x36FZwmZ1a3JPXp00eJiYn69NNPdfbsWZUvX95hdCZXBAcHq2LFitq5c2eh137//Xd5eHhc9H+iIyIitG3bNhmG4bBjd7asSxUVFaXTp0/bjzC5quD9L1++/EXPwxlXTvs06xsXF6cJEybo3//+t7799lsFBwc7/U/bkSNHlJOT43DUadeuXZJkHwQgKipKW7Zs0R133OHyqakFozPu3LnTfmpfgZ07d17UzV+Dg4Pl5+dXou//35X091UgKipKQ4cO1dChQ7V79241adJEEyZM0KxZs+x9brnlFt1yyy169dVXNWfOHD300EOaO3euBgwY4PJ6/XPZNptNv/32m8MpZH+3fPlyHT9+XAsXLlS7du3s7Xv37i3Ut6Sf298/r3/6/fffFRQUVGo3JQ4MDCy0vZQubDP/fiqwJPuocr1791ZeXp7uv/9+vfrqq0pKSrrkYdwjIiK0Z8+eQu3O2i6Gq9uLJUuW6OOPP9YLL7yg2bNnKz4+XmvXri32jIeoqCgtXbpUJ06cKPKoU0REhGw2m3bv3m2/Qbgkpaen6+TJk1fkRsxAaeFUPaCUnD17VgsXLtS9996rnj17Fno89dRTOnXqlH0Y2B49emjLli1Oh+0u+Mtajx49lJmZ6fRITUGfiIgIeXp6Fro+xmwkpL8r+Avf3/+iZxiG/vWvfzn0Cw4OVrt27TR16lQdOHDAaT0FgoKCdPfdd2vWrFmaPXu27rrrrou+u72np6fuvPNOffnllw5D9Kanp2vOnDm69dZb5efnd1Hzvueee3TkyBGH67HOnDmjDz/88KLmV5xevXppzZo19r/q/t3Jkyd1/vz5YqevWrWqOnTooA8++EBHjx4t9Prfhxl3hY+Pj9P/SDpTMApjUf1vvvlm3Xzzzfr444/1+eefq0+fPk7/43X+/Hl98MEH9ud5eXn64IMPFBwcrObNm0u68H4dPnxYH330UaHpz549W+xoiS1atFDVqlU1ZcoUh9PYvv32W+3YsUOdO3cu0fr+nYeHh7p166Z///vfDkMtFyjqL+Il/X2dOXNGf/31l0NbVFSUKlWqZF+HP//8s9ByCgJOaZyu161bN3l4eGjMmDGFjhwVLNfZ+uTl5Tnd5vj4+JTo1L2wsDA1adJEM2bMcPhubdu2Td99953uueeei1kdp6KiovTzzz87DB//1VdfFTrd9/jx4w7Pvby81KBBAxmGUSrXl3Xq1Elr1qzR5s2b7W0nTpwotfv+ubK9OHnypAYMGKBWrVpp3Lhx+vjjj7Vx40aNGzeu2GX06NFDhmE4PQJX8P0o+Oz+OWpowZHki/ktAu7CESeglCxevFinTp3Sfffd5/T1W265xX4z3N69e+v555/XggUL9MADD6h///5q3ry5Tpw4ocWLF2vKlClq3Lix4uLi9H//939KTEzUunXr1LZtW+Xk5Og///mPnnzySXXt2lX+/v72YWQtFouioqL01VdfFXv9xz/Vq1dPUVFReu6553T48GH5+fnp888/d3pO+TvvvKNbb71VzZo102OPPaaaNWtq3759+vrrrx3+AyBdOPpQMOjC2LFjS/5mOvHKK6/o+++/16233qonn3xS5cqV0wcffKDc3Fy9/vrrFz3fgQMHatKkSYqLi9OGDRsUFhammTNn2gNCaXr++ee1ePFi3XvvvfbhdXNycrR161YtWLBA+/btMw2XkydP1q233qpGjRpp4MCBqlWrltLT07VmzRodOnRIW7Zscbmu5s2b6/3339crr7yi2rVrq2rVqoWO0hSoUKGCGjRooHnz5qlOnTqqXLmyGjZs6HDdT1xcnJ577jlJKvI0vWrVqmn8+PHat2+f6tSpo3nz5mnz5s368MMP7UdXH3nkEX322Wf6n//5H/3www9q06aN8vPz9fvvv+uzzz7T0qVLnQ7SIF34K/v48eOVkJCg9u3bq2/fvvbhyCMjI/Xss8+6/D5JF+5J9d1336l9+/b2IdKPHj2q+fPna+XKlU5PbSrp72vXrl2644471KtXLzVo0EDlypXTF198ofT0dPXp00eSNGPGDL333nvq3r27oqKidOrUKX300Ufy8/MrlXBRu3ZtDRs2TGPHjlXbtm11//33y2q16pdfflG1atWUnJys1q1bKzAwUPHx8Xr66adlsVg0c+ZMp8GxefPmmjdvnhITE9WyZUv5+vqqS5cuTpf9xhtv6O6771ZMTIweffRR+3Dk/v7+9ntSlYYBAwZowYIFuuuuu9SrVy+lpqZq1qxZhYahv/POOxUaGqo2bdooJCREO3bs0KRJk9S5c+dC1+xdjBdeeEGzZs1Sx44dNXjwYPtw5DfccINOnDhR4qN1b731VqHtlYeHh15++eUSby+GDBmi48eP6z//+Y88PT111113acCAAXrllVfUtWtXNW7c2Omyb7vtNj3yyCN65513tHv3bt11112y2WxasWKFbrvtNj311FNq3Lix4uPj9eGHH9pP81y3bp1mzJihbt262QdSAq4KV24AP+Da1qVLF8Pb29vIyckpsk+/fv2M8uXLG5mZmYZhXBh69qmnnjKqV69ueHl5GTVq1DDi4+PtrxvGhWF/hw0bZtSsWdMoX768ERoaavTs2dNhWO5jx44ZPXr0MCpWrGgEBgYajz/+uLFt2zanw5H7+Pg4re23334zYmNjDV9fXyMoKMgYOHCgsWXLlkLzMAzD2LZtm9G9e3cjICDA8Pb2NurWrWsMHz680Dxzc3ONwMBAw9/f32FI6OIUNRy5YVwY2rpTp06Gr6+vUbFiReO2224zVq9e7dDHlaGlC+zfv9+47777jIoVKxpBQUHGkCFDjCVLlpT6cOSGYRinTp0ykpKSjNq1axteXl5GUFCQ0bp1a+PNN9+0D8Nd3HtgGIaRmppqxMXFGaGhoUb58uWN6tWrG/fee6+xYMEC0/fB2VDZaWlpRufOnY1KlSoZkkyHJl+9erXRvHlzw8vLy+nQ5EePHjU8PT2NOnXqOJ2+ffv2xk033WSsX7/eiImJMby9vY2IiAhj0qRJhfrm5eUZ48ePN2666SbDarUagYGBRvPmzY3Ro0cbWVlZxdZpGIYxb948o2nTpobVajUqV65sPPTQQ8ahQ4cc+rj6ndm/f78RFxdnBAcHG1ar1ahVq5YxaNAgIzc31zAM5+9xSX5fmZmZxqBBg4x69eoZPj4+hr+/vxEdHe0wVP7GjRuNvn37GjfccINhtVqNqlWrGvfee6+xfv16hxr/+bmUdDjyAlOnTrW/b4GBgUb79u3tt1gwDMNYtWqVccsttxgVKlQwqlWrZrzwwgvG0qVLC6336dOnjQcffNAICAgwJNl/P86GIzcMw/jPf/5jtGnTxqhQoYLh5+dndOnSxfjtt9+c1vzPYbidDQ1elAkTJhjVq1c3rFar0aZNG2P9+vWFhiP/4IMPjHbt2hlVqlQxrFarERUVZTz//PMO37uihiN3tk345/wNwzA2bdpktG3b1rBarUaNGjWM5ORk45133jEkGWlpacWuQ8H74Ozh6elp72e2vfjyyy8L3R7AMAwjOzvbiIiIMBo3bmzfNjnbBp4/f9544403jHr16hleXl5GcHCwcffddxsbNmyw9zl37pwxevRo+34sPDzcSEpKchgm3dX3DnAHi2FwtR2Ay+P8+fOqVq2aunTpok8++cTd5eAKyczMVFhYmEaMGKHhw4cXer1Dhw7KzMx0+Voh4HrwzDPP6IMPPtDp06dLdEsFAFcO1zgBuGwWLVqkY8eOOVwQj2vf9OnTlZ+fr0ceecTdpQBl2tmzZx2eHz9+XDNnztStt95KaALKIK5xAlDq1q5dq19//VVjx45V06ZN7ferwbVt2bJl+u233/Tqq6+qW7du9tHxADgXExOjDh06qH79+kpPT9cnn3yi7Oxsp0dqAbgfwQlAqXv//fc1a9YsNWnSRNOnT3d3ObhCxowZo9WrV6tNmzZ699133V0OUObdc889WrBggT788ENZLBY1a9ZMn3zyicMw7wDKDq5xAgAAAAATXOMEAAAAACYITgAAAABg4rq7xslms+nIkSOqVKlSiW8uBwAAAODaYxiGTp06pWrVqsnDo/hjStddcDpy5IjCw8PdXQYAAACAMuLgwYOqUaNGsX2uu+BUqVIlSRfeHD8/PzdXAwAAAMBdsrOzFR4ebs8IxbnuglPB6Xl+fn4EJwAAAAAluoSHwSEAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwESZCE6TJ09WZGSkvL29FR0drXXr1hXZt0OHDrJYLIUenTt3voIVAwAAALieuD04zZs3T4mJiRo5cqQ2btyoxo0bq1OnTsrIyHDaf+HChTp69Kj9sW3bNnl6euqBBx64wpUDAAAAuF64PTi99dZbGjhwoBISEtSgQQNNmTJFFStW1NSpU532r1y5skJDQ+2P77//XhUrViQ4AQAAALhs3Bqc8vLytGHDBsXGxtrbPDw8FBsbqzVr1pRoHp988on69OkjHx8fp6/n5uYqOzvb4QEAAAAArnBrcMrMzFR+fr5CQkIc2kNCQpSWlmY6/bp167Rt2zYNGDCgyD7Jycny9/e3P8LDwy+5bgAAAADXF7efqncpPvnkEzVq1EitWrUqsk9SUpKysrLsj4MHD17BCgEAAABcC8q5c+FBQUHy9PRUenq6Q3t6erpCQ0OLnTYnJ0dz587VmDFjiu1ntVpltVovuVYAAAAA1y+3HnHy8vJS8+bNlZKSYm+z2WxKSUlRTExMsdPOnz9fubm5evjhhy93mQAAAACuc2494iRJiYmJio+PV4sWLdSqVStNnDhROTk5SkhIkCTFxcWpevXqSk5Odpjuk08+Ubdu3VSlShV3lA0AAADgOuL24NS7d28dO3ZMI0aMUFpampo0aaIlS5bYB4w4cOCAPDwcD4zt3LlTK1eu1HfffeeOkgEAAABcZyyGYRjuLuJKys7Olr+/v7KysuTn5+fucgAAwDXIYnF3BUDZVlYSiCvZ4KoeVQ8AAAAArgSCEwAAAACYIDgBAAAAgAmCEwAAAACYcPuoeuACUsBMWbmAFAAAXL844gQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGDC7cFp8uTJioyMlLe3t6Kjo7Vu3bpi+588eVKDBg1SWFiYrFar6tSpo2+++eYKVQsAAADgelTOnQufN2+eEhMTNWXKFEVHR2vixInq1KmTdu7cqapVqxbqn5eXp44dO6pq1apasGCBqlevrv379ysgIODKFw8AAADgumExDMNw18Kjo6PVsmVLTZo0SZJks9kUHh6uwYMH66WXXirUf8qUKXrjjTf0+++/q3z58iVaRm5urnJzc+3Ps7OzFR4erqysLPn5+ZXOilwii8XdFQBlm/u2UgBwcdi3A8UrK/v27Oxs+fv7lygbuO1Uvby8PG3YsEGxsbH/LcbDQ7GxsVqzZo3TaRYvXqyYmBgNGjRIISEhatiwocaNG6f8/Pwil5OcnCx/f3/7Izw8vNTXBQAAAMC1zW3BKTMzU/n5+QoJCXFoDwkJUVpamtNp/vjjDy1YsED5+fn65ptvNHz4cE2YMEGvvPJKkctJSkpSVlaW/XHw4MFSXQ8AAAAA1z63XuPkKpvNpqpVq+rDDz+Up6enmjdvrsOHD+uNN97QyJEjnU5jtVpltVqvcKUAAAAAriVuC05BQUHy9PRUenq6Q3t6erpCQ0OdThMWFqby5cvL09PT3la/fn2lpaUpLy9PXl5el7VmAAAAANcnt52q5+XlpebNmyslJcXeZrPZlJKSopiYGKfTtGnTRnv27JHNZrO37dq1S2FhYYQmAAAAAJeNW+/jlJiYqI8++kgzZszQjh079MQTTygnJ0cJCQmSpLi4OCUlJdn7P/HEEzpx4oSGDBmiXbt26euvv9a4ceM0aNAgd60CAAAAgOuAW69x6t27t44dO6YRI0YoLS1NTZo00ZIlS+wDRhw4cEAeHv/NduHh4Vq6dKmeffZZ3XzzzapevbqGDBmiF1980V2rAAAAAOA64Nb7OLmDK2O1Xync6wEo3vW1lQJwLWDfDhSvrOzbr4r7OAEAAADA1YLgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmCE4AAAAAYILgBAAAAAAmykRwmjx5siIjI+Xt7a3o6GitW7euyL7Tp0+XxWJxeHh7e1/BagEAAABcb9wenObNm6fExESNHDlSGzduVOPGjdWpUydlZGQUOY2fn5+OHj1qf+zfv/8KVgwAAADgeuP24PTWW29p4MCBSkhIUIMGDTRlyhRVrFhRU6dOLXIai8Wi0NBQ+yMkJKTIvrm5ucrOznZ4AAAAAIAr3Bqc8vLytGHDBsXGxtrbPDw8FBsbqzVr1hQ53enTpxUREaHw8HB17dpV27dvL7JvcnKy/P397Y/w8PBSXQcAAAAA1z63BqfMzEzl5+cXOmIUEhKitLQ0p9PUrVtXU6dO1ZdffqlZs2bJZrOpdevWOnTokNP+SUlJysrKsj8OHjxY6usBAAAA4NpWzt0FuComJkYxMTH2561bt1b9+vX1wQcfaOzYsYX6W61WWa3WK1kiAAAAgGuMW484BQUFydPTU+np6Q7t6enpCg0NLdE8ypcvr6ZNm2rPnj2Xo0QAAAAAcG9w8vLyUvPmzZWSkmJvs9lsSklJcTiqVJz8/Hxt3bpVYWFhl6tMAAAAANc5t5+ql5iYqPj4eLVo0UKtWrXSxIkTlZOTo4SEBElSXFycqlevruTkZEnSmDFjdMstt6h27do6efKk3njjDe3fv18DBgxw52oAAAAAuIa5PTj17t1bx44d04gRI5SWlqYmTZpoyZIl9gEjDhw4IA+P/x4Y+/PPPzVw4EClpaUpMDBQzZs31+rVq9WgQQN3rQIAAACAa5zFMAzD3UVcSdnZ2fL391dWVpb8/PzcXY4kyWJxdwVA2XZ9baUAXAvYtwPFKyv7dleygdtvgAsAAAAAZR3BCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMuBycIiMjNWbMGB04cOBy1AMAAAAAZY7LwemZZ57RwoULVatWLXXs2FFz585Vbm7u5agNAAAAAMqEiwpOmzdv1rp161S/fn0NHjxYYWFheuqpp7Rx48bLUSMAAAAAuJXFMAzjUmZw7tw5vffee3rxxRd17tw5NWrUSE8//bQSEhJksVhKq85Sk52dLX9/f2VlZcnPz8/d5UiSyuDbBJQpl7aVAoArj307ULyysm93JRtc9OAQ586d02effab77rtPQ4cOVYsWLfTxxx+rR48eevnll/XQQw+VeF6TJ09WZGSkvL29FR0drXXr1pVourlz58pisahbt24XuRYAAAAAYK6cqxNs3LhR06ZN06effioPDw/FxcXp7bffVr169ex9unfvrpYtW5ZofvPmzVNiYqKmTJmi6OhoTZw4UZ06ddLOnTtVtWrVIqfbt2+fnnvuObVt29bVVQAAAAAAl7h8xKlly5bavXu33n//fR0+fFhvvvmmQ2iSpJo1a6pPnz4lmt9bb72lgQMHKiEhQQ0aNNCUKVNUsWJFTZ06tchp8vPz9dBDD2n06NGqVauWq6sAAAAAAC5x+YjTH3/8oYiIiGL7+Pj4aNq0aabzysvL04YNG5SUlGRv8/DwUGxsrNasWVPkdGPGjFHVqlX16KOPasWKFcUuIzc312HUv+zsbNO6AAAAAODvXD7ilJGRobVr1xZqX7t2rdavX+/SvDIzM5Wfn6+QkBCH9pCQEKWlpTmdZuXKlfrkk0/00UcflWgZycnJ8vf3tz/Cw8NdqhEAAAAAXA5OgwYN0sGDBwu1Hz58WIMGDSqVoopy6tQpPfLII/roo48UFBRUommSkpKUlZVlfzirHQAAAACK4/Kper/99puaNWtWqL1p06b67bffXJpXUFCQPD09lZ6e7tCenp6u0NDQQv1TU1O1b98+denSxd5ms9kkSeXKldPOnTsVFRXlMI3VapXVanWpLgAAAAD4O5ePOFmt1kJBR5KOHj2qcuVcy2FeXl5q3ry5UlJS7G02m00pKSmKiYkp1L9evXraunWrNm/ebH/cd999uu2227R582ZOwwMAAABwWbh8xOnOO+9UUlKSvvzyS/n7+0uSTp48qZdfflkdO3Z0uYDExETFx8erRYsWatWqlSZOnKicnBwlJCRIkuLi4lS9enUlJyfL29tbDRs2dJg+ICBAkgq1AwAAAEBpcTk4vfnmm2rXrp0iIiLUtGlTSdLmzZsVEhKimTNnulxA7969dezYMY0YMUJpaWlq0qSJlixZYh8w4sCBA/LwuOj79AIAAADAJbMYhmG4OlFOTo5mz56tLVu2qEKFCrr55pvVt29flS9f/nLUWKqys7Pl7++vrKws+fn5ubscSZLF4u4KgLLN9a0UALgX+3ageGVl3+5KNnD5iJN04T5Njz322EUVBwAAAABXm4sKTtKF0fUOHDigvLw8h/b77rvvkosCAAAAgLLE5eD0xx9/qHv37tq6dassFosKzvSz/P9j0vn5+aVbIQAAAAC4mcujLgwZMkQ1a9ZURkaGKlasqO3bt+unn35SixYttHz58stQIgAAAAC4l8tHnNasWaNly5YpKChIHh4e8vDw0K233qrk5GQ9/fTT2rRp0+WoEwAAAADcxuUjTvn5+apUqZIkKSgoSEeOHJEkRUREaOfOnaVbHQAAAACUAS4fcWrYsKG2bNmimjVrKjo6Wq+//rq8vLz04YcfqlatWpejRgAAAABwK5eD0//+7/8qJydHkjRmzBjde++9atu2rapUqaJ58+aVeoEAAAAA4G4XdQPcfzpx4oQCAwPtI+uVZdwAF7j6lJWb5AFASbFvB4pXVvbtrmQDl65xOnfunMqVK6dt27Y5tFeuXPmqCE0AAAAAcDFcCk7ly5fXDTfcwL2aAAAAAFxXXB5Vb9iwYXr55Zd14sSJy1EPAAAAAJQ5Lg8OMWnSJO3Zs0fVqlVTRESEfHx8HF7fuHFjqRUHAAAAAGWBy8GpW7dul6EMAAAAACi7SmVUvasJo+oBV5/raysF4FrAvh0oXlnZt1+2UfUAAAAA4Hrk8ql6Hh4exQ49zoh7AAAAAK41LgenL774wuH5uXPntGnTJs2YMUOjR48utcIAAAAAoKwotWuc5syZo3nz5unLL78sjdldNlzjBFx9ysp50ABQUuzbgeKVlX27W65xuuWWW5SSklJaswMAAACAMqNUgtPZs2f1zjvvqHr16qUxOwAAAAAoU1y+xikwMNBhcAjDMHTq1ClVrFhRs2bNKtXiAAAAAKAscDk4vf322w7BycPDQ8HBwYqOjlZgYGCpFgcAAAAAZYHLwalfv36XoQwAAAAAKLtcvsZp2rRpmj9/fqH2+fPna8aMGaVSFAAAAACUJS4Hp+TkZAUFBRVqr1q1qsaNG1cqRQEAAABAWeJycDpw4IBq1qxZqD0iIkIHDhwolaIAAAAAoCxxOThVrVpVv/76a6H2LVu2qEqVKqVSFAAAAACUJS4Hp759++rpp5/WDz/8oPz8fOXn52vZsmUaMmSI+vTpczlqBAAAAAC3cnlUvbFjx2rfvn264447VK7chcltNpvi4uK4xgkAAADANcliGIZxMRPu3r1bmzdvVoUKFdSoUSNFRESUdm2XRXZ2tvz9/ZWVlSU/Pz93lyNJ+tttsQA4cXFbKQBwH/btQPHKyr7dlWzg8hGnAjfeeKNuvPHGi50cAAAAAK4aLl/j1KNHD40fP75Q++uvv64HHnigVIoCAAAAgLLE5eD0008/6Z577inUfvfdd+unn34qlaIAAAAAoCxxOTidPn1aXl5ehdrLly+v7OzsUikKAAAAAMoSl4NTo0aNNG/evELtc+fOVYMGDUqlKAAAAAAoS1weHGL48OG6//77lZqaqttvv12SlJKSojlz5mjBggWlXiAAAAAAuJvLwalLly5atGiRxo0bpwULFqhChQpq3Lixli1bpsqVK1+OGgEAAADArS76Pk4FsrOz9emnn+qTTz7Rhg0blJ+fX1q1XRbcxwm4+pSVez0AQEmxbweKV1b27a5kA5evcSrw008/KT4+XtWqVdOECRN0++236+eff77Y2QEAAABAmeXSqXppaWmaPn26PvnkE2VnZ6tXr17Kzc3VokWLGBgCAAAAwDWrxEecunTporp16+rXX3/VxIkTdeTIEb377ruXszYAAAAAKBNKHJy+/fZbPfrooxo9erQ6d+4sT0/PUiti8uTJioyMlLe3t6Kjo7Vu3boi+y5cuFAtWrRQQECAfHx81KRJE82cObPUagEAAACAfypxcFq5cqVOnTql5s2bKzo6WpMmTVJmZuYlFzBv3jwlJiZq5MiR2rhxoxo3bqxOnTopIyPDaf/KlStr2LBhWrNmjX799VclJCQoISFBS5cuveRaAAAAAMAZl0fVy8nJ0bx58zR16lStW7dO+fn5euutt9S/f39VqlTJ5QKio6PVsmVLTZo0SZJks9kUHh6uwYMH66WXXirRPJo1a6bOnTtr7Nixpn0ZVQ+4+pSVkXcAoKTYtwPFKyv79ss6qp6Pj4/69++vlStXauvWrRo6dKhee+01Va1aVffdd59L88rLy9OGDRsUGxv734I8PBQbG6s1a9aYTm8YhlJSUrRz5061a9fOaZ/c3FxlZ2c7PAAAAADAFRc9HLkk1a1bV6+//roOHTqkTz/91OXpMzMzlZ+fr5CQEIf2kJAQpaWlFTldVlaWfH195eXlpc6dO+vdd99Vx44dnfZNTk6Wv7+//REeHu5ynQAAAACub5cUnAp4enqqW7duWrx4cWnMzlSlSpW0efNm/fLLL3r11VeVmJio5cuXO+2blJSkrKws++PgwYNXpEYAAAAA1w6X7uNU2oKCguTp6an09HSH9vT0dIWGhhY5nYeHh2rXri1JatKkiXbs2KHk5GR16NChUF+r1Sqr1VqqdQMAAAC4vpTKEaeL5eXlpebNmyslJcXeZrPZlJKSopiYmBLPx2azKTc393KUCAAAAADuPeIkSYmJiYqPj1eLFi3UqlUrTZw4UTk5OUpISJAkxcXFqXr16kpOTpZ04ZqlFi1aKCoqSrm5ufrmm280c+ZMvf/+++5cDQAAAADXMLcHp969e+vYsWMaMWKE0tLS1KRJEy1ZssQ+YMSBAwfk4fHfA2M5OTl68skndejQIVWoUEH16tXTrFmz1Lt3b3etAgAAAIBrnMv3cbracR8n4OpzfW2lAFwL2LcDxSsr+/bLeh8nAAAAALjeEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwATBCQAAAABMEJwAAAAAwESZCE6TJ09WZGSkvL29FR0drXXr1hXZ96OPPlLbtm0VGBiowMBAxcbGFtsfAAAAAC6V24PTvHnzlJiYqJEjR2rjxo1q3LixOnXqpIyMDKf9ly9frr59++qHH37QmjVrFB4erjvvvFOHDx++wpUDAAAAuF5YDMMw3FlAdHS0WrZsqUmTJkmSbDabwsPDNXjwYL300kum0+fn5yswMFCTJk1SXFycaf/s7Gz5+/srKytLfn5+l1x/abBY3F0BULa5dysFAK5j3w4Ur6zs213JBm494pSXl6cNGzYoNjbW3ubh4aHY2FitWbOmRPM4c+aMzp07p8qVKzt9PTc3V9nZ2Q4PAAAAAHCFW4NTZmam8vPzFRIS4tAeEhKitLS0Es3jxRdfVLVq1RzC198lJyfL39/f/ggPD7/kugEAAABcX9x+jdOleO211zR37lx98cUX8vb2dtonKSlJWVlZ9sfBgwevcJUAAAAArnbl3LnwoKAgeXp6Kj093aE9PT1doaGhxU775ptv6rXXXtN//vMf3XzzzUX2s1qtslqtpVIvAAAAgOuTW484eXl5qXnz5kpJSbG32Ww2paSkKCYmpsjpXn/9dY0dO1ZLlixRixYtrkSpAAAAAK5jbj3iJEmJiYmKj49XixYt1KpVK02cOFE5OTlKSEiQJMXFxal69epKTk6WJI0fP14jRozQnDlzFBkZab8WytfXV76+vm5bDwAAAADXLrcHp969e+vYsWMaMWKE0tLS1KRJEy1ZssQ+YMSBAwfk4fHfA2Pvv/++8vLy1LNnT4f5jBw5UqNGjbqSpQMAAAC4Trj9Pk5XGvdxAq4+19dWCsC1gH07ULyysm+/au7jBAAAAABXA4ITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACYITAAAAAJggOAEAAACACbcHp8mTJysyMlLe3t6Kjo7WunXriuy7fft29ejRQ5GRkbJYLJo4ceKVKxQAAADAdcutwWnevHlKTEzUyJEjtXHjRjVu3FidOnVSRkaG0/5nzpxRrVq19Nprryk0NPQKVwsAAADgemUxDMNw18Kjo6PVsmVLTZo0SZJks9kUHh6uwYMH66WXXip22sjISD3zzDN65plniu2Xm5ur3Nxc+/Ps7GyFh4crKytLfn5+l7wOpcFicXcFQNnmvq0UAFwc9u1A8crKvj07O1v+/v4lygZuO+KUl5enDRs2KDY29r/FeHgoNjZWa9asKbXlJCcny9/f3/4IDw8vtXkDAAAAuD64LThlZmYqPz9fISEhDu0hISFKS0srteUkJSUpKyvL/jh48GCpzRsAAADA9aGcuwu43KxWq6xWq7vLAAAAAHAVc9sRp6CgIHl6eio9Pd2hPT09nYEfAAAAAJQpbgtOXl5eat68uVJSUuxtNptNKSkpiomJcVdZAAAAAFCIW0/VS0xMVHx8vFq0aKFWrVpp4sSJysnJUUJCgiQpLi5O1atXV3JysqQLA0r89ttv9n8fPnxYmzdvlq+vr2rXru229QAAAABwbXNrcOrdu7eOHTumESNGKC0tTU2aNNGSJUvsA0YcOHBAHh7/PSh25MgRNW3a1P78zTff1Jtvvqn27dtr+fLlV7p8AAAAANcJt97HyR1cGav9SuFeD0Dxrq+tFIBrAft2oHhlZd9+VdzHCQAAAACuFgQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBBcAIAAAAAEwQnAAAAADBRJoLT5MmTFRkZKW9vb0VHR2vdunXF9p8/f77q1asnb29vNWrUSN98880VqhQAAADA9cjtwWnevHlKTEzUyJEjtXHjRjVu3FidOnVSRkaG0/6rV69W37599eijj2rTpk3q1q2bunXrpm3btl3hygEAAABcLyyGYRjuLCA6OlotW7bUpEmTJEk2m03h4eEaPHiwXnrppUL9e/furZycHH311Vf2tltuuUVNmjTRlClTTJeXnZ0tf39/ZWVlyc/Pr/RW5BJYLO6uACjb3LuVAgDXsW8HildW9u2uZINyV6gmp/Ly8rRhwwYlJSXZ2zw8PBQbG6s1a9Y4nWbNmjVKTEx0aOvUqZMWLVrktH9ubq5yc3Ptz7OysiRdeJMAXB34uQIAcG0pK/v2gkxQkmNJbg1OmZmZys/PV0hIiEN7SEiIfv/9d6fTpKWlOe2flpbmtH9ycrJGjx5dqD08PPwiqwZwpfn7u7sCAABQmsravv3UqVPyNynKrcHpSkhKSnI4QmWz2XTixAlVqVJFFo6j4x+ys7MVHh6ugwcPlplTOQEAwMVj347iGIahU6dOqVq1aqZ93RqcgoKC5OnpqfT0dIf29PR0hYaGOp0mNDTUpf5Wq1VWq9WhLSAg4OKLxnXBz8+PjSsAANcQ9u0oitmRpgJuHVXPy8tLzZs3V0pKir3NZrMpJSVFMTExTqeJiYlx6C9J33//fZH9AQAAAOBSuf1UvcTERMXHx6tFixZq1aqVJk6cqJycHCUkJEiS4uLiVL16dSUnJ0uShgwZovbt22vChAnq3Lmz5s6dq/Xr1+vDDz9052oAAAAAuIa5PTj17t1bx44d04gRI5SWlqYmTZpoyZIl9gEgDhw4IA+P/x4Ya926tebMmaP//d//1csvv6wbb7xRixYtUsOGDd21CriGWK1WjRw5stDpnQAA4OrEvh2lxe33cQIAAACAss6t1zgBAAAAwNWA4AQAAAAAJghOAAAAAGCC4AQAAIBryr59+2SxWLR58+YSTzN9+vQreq/Pfv36qVu3bldsebh0BCfg/zt27JieeOIJ3XDDDbJarQoNDVWnTp20atUqd5cGAMBVoazsS8PDw3X06NFSH3WZsHN9c/tw5EBZ0aNHD+Xl5WnGjBmqVauW0tPTlZKSouPHj7u7NAAArgplZV/q6emp0NDQK7pMXPs44gRIOnnypFasWKHx48frtttuU0REhFq1aqWkpCTdd9997i4PAIAy71L2pc8995zuvfde+/OJEyfKYrFoyZIl9rbatWvr448/tj//+OOPVb9+fXl7e6tevXp677337K85O1Vv8eLFuvHGG+Xt7a3bbrtNM2bMkMVi0cmTJx1qWbp0qerXry9fX1/dddddOnr0qCRp1KhRmjFjhr788ktZLBZZLBYtX75cknTw4EH16tVLAQEBqly5srp27ap9+/bZ55mfn6/ExEQFBASoSpUqeuGFF8Qdga4+BCdAkq+vr3x9fbVo0SLl5ua6uxwAAK46l7Ivbd++vVauXKn8/HxJ0o8//qigoCB7MDl8+LBSU1PVoUMHSdLs2bM1YsQIvfrqq9qxY4fGjRun4cOHa8aMGU7nv3fvXvXs2VPdunXTli1b9Pjjj2vYsGGF+p05c0ZvvvmmZs6cqZ9++kkHDhzQc889J+lCuOvVq5c9TB09elStW7fWuXPn1KlTJ1WqVEkrVqzQqlWr7KErLy9PkjRhwgRNnz5dU6dO1cqVK3XixAl98cUXLr1HKAMMAIZhGMaCBQuMwMBAw9vb22jdurWRlJRkbNmyxd1lAQBw1bjYfemff/5peHh4GL/88oths9mMypUrG8nJyUZ0dLRhGIYxa9Yso3r16vb+UVFRxpw5cxzmMXbsWCMmJsYwDMPYu3evIcnYtGmTYRiG8eKLLxoNGzZ06D9s2DBDkvHnn38ahmEY06ZNMyQZe/bssfeZPHmyERISYn8eHx9vdO3a1WE+M2fONOrWrWvYbDZ7W25urlGhQgVj6dKlhmEYRlhYmPH666/bXz937pxRo0aNQvNC2cYRJ+D/69Gjh44cOaLFixfrrrvu0vLly9WsWTNNnz7d3aUBAHBVuNh9aUBAgBo3bqzly5dr69at8vLy0mOPPaZNmzbp9OnT+vHHH9W+fXtJUk5OjlJTU/Xoo4/aj3L5+vrqlVdeUWpqqtP579y5Uy1btnRoa9WqVaF+FStWVFRUlP15WFiYMjIyiq19y5Yt2rNnjypVqmSvpXLlyvrrr7+UmpqqrKwsHT16VNHR0fZpypUrpxYtWhQ7X5Q9DA4B/I23t7c6duyojh07avjw4RowYIBGjhypfv36ubs0AACuChe7L+3QoYOWL18uq9Wq9u3bq3Llyqpfv75WrlypH3/8UUOHDpUknT59WpL00UcfOYQR6cKgEJeifPnyDs8tFovptUinT59W8+bNNXv27EKvBQcHX1I9KFs44gQUo0GDBsrJyXF3GQAAXLVKui8tuM4pJSXFfi1Thw4d9Omnn2rXrl32tpCQEFWrVk1//PGHateu7fCoWbOm03nXrVtX69evd2j75ZdfXF4XLy8v+3VYBZo1a6bdu3eratWqherx9/eXv7+/wsLCtHbtWvs058+f14YNG1xePtyL4ARIOn78uG6//XbNmjVLv/76q/bu3av58+fr9ddfV9euXd1dHgAAZd6l7kvbtWunU6dO6auvvnIITrNnz1ZYWJjq1Klj7zt69GglJyfrnXfe0a5du7R161ZNmzZNb731ltN5P/744/r999/14osvateuXfrss8/spw9aLJYSr2NkZKR+/fVX7dy5U5mZmTp37pweeughBQUFqWvXrlqxYoX27t2r5cuX6+mnn9ahQ4ckSUOGDNFrr72mRYsW6ffff9eTTz5ZaDQ/lH2cqgfowkhA0dHRevvtt5Wamqpz584pPDxcAwcO1Msvv+zu8gAAKPMudV8aGBioRo0aKT09XfXq1ZN0IUzZbDb79U0FBgwYoIoVK+qNN97Q888/Lx8fHzVq1EjPPPOM03nXrFlTCxYs0NChQ/Wvf/1LMTExGjZsmJ544glZrdYSr+PAgQO1fPlytWjRQqdPn9YPP/ygDh066KefftKLL76o+++/X6dOnVL16tV1xx13yM/PT5I0dOhQHT16VPHx8fLw8FD//v3VvXt3ZWVllXjZcD+LYXbiJgAAAHCNefXVVzVlyhQdPHjQ3aXgKsERJwAAAFzz3nvvPbVs2VJVqlTRqlWr9MYbb+ipp55yd1m4ihCcAAAAcFnNnj1bjz/+uNPXIiIitH379stew+7du/XKK6/oxIkTuuGGGzR06FAlJSVd9uXi2sGpegAAALisTp06pfT0dKevlS9fXhEREVe4IsB1BCcAAAAAMMFw5AAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgCAa9aZM2fUo0cP+fn5yWKx6OTJk1e8hlGjRqlJkyZXfLkAgNJFcAIAmLJYLMU+Ro0a5e4SnZoxY4ZWrFih1atX6+jRo/L39y/UZ/r06QoICLhsNTz33HNKSUm5bPMHAFwZ3AAXAGDq6NGj9n/PmzdPI0aM0M6dO+1tvr6+7ijLVGpqqurXr6+GDRu6rQZfX98y+/4AAEqOI04AAFOhoaH2h7+/vywWi0JDQ1WpUiXVqVNHS5Yscei/aNEi+fj46NSpU9q3b58sFovmzp2r1q1by9vbWw0bNtSPP/7oMM22bdt09913y9fXVyEhIXrkkUeUmZlZbF2ff/65brrpJlmtVkVGRmrChAn21zp06KAJEybop59+ksViUYcOHS5q3U+ePKkBAwYoODhYfn5+uv3227VlyxZJ0rFjxxQaGqpx48bZ+69evVpeXl72o0zOTtWbOnWqve6wsDA99dRT9tcOHDigrl27ytfXV35+furVq5fDjUML5jdz5kxFRkbK399fffr00alTpy5q/QAAJUNwAgBcNB8fH/Xp00fTpk1zaJ82bZp69uypSpUq2duef/55DR06VJs2bVJMTIy6dOmi48ePS7oQTm6//XY1bdpU69ev15IlS5Senq5evXoVuewNGzaoV69e6tOnj7Zu3apRo0Zp+PDhmj59uiRp4cKFGjhwoGJiYnT06FEtXLjwotbxgQceUEZGhr799ltt2LBBzZo10x133KETJ04oODhYU6dO1ahRo7R+/XqdOnVKjzzyiJ566indcccdTuf3/vvva9CgQXrssce0detWLV68WLVr15Yk2Ww2de3aVSdOnNCPP/6o77//Xn/88Yd69+7tMI/U1FQtWrRIX331lb766iv9+OOPeu211y5q/QAAJWQAAOCCadOmGf7+/vbna9euNTw9PY0jR44YhmEY6enpRrly5Yzly5cbhmEYe/fuNSQZr732mn2ac+fOGTVq1DDGjx9vGIZhjB071rjzzjsdlnPw4EFDkrFz506ndTz44INGx44dHdqef/55o0GDBvbnQ4YMMdq3b+/S+vzdihUrDD8/P+Ovv/5yaI+KijI++OAD+/Mnn3zSqFOnjvHggw8ajRo1cug/cuRIo3Hjxvbn1apVM4YNG+Z0ed99953h6elpHDhwwN62fft2Q5Kxbt06+/wqVqxoZGdnO6x3dHR0sesJALg0HHECAFySVq1a6aabbtKMGTMkSbNmzVJERITatWvn0C8mJsb+73LlyqlFixbasWOHJGnLli364Ycf7NcD+fr6ql69epIuHF1xZseOHWrTpo1DW5s2bbR7927l5+eXyrpt2bJFp0+fVpUqVRxq27t3r0Ndb775ps6fP6/58+dr9uzZslqtTueXkZGhI0eOFHk0aseOHQoPD1d4eLi9rUGDBgoICLC/V5IUGRnpcDQvLCxMGRkZl7q6AIBiMDgEAOCSDRgwQJMnT9ZLL72kadOmKSEhQRaLpcTTnz59Wl26dNH48eMLvRYWFlaapbrk9OnTCgsL0/Llywu99veR+FJTU3XkyBHZbDbt27dPjRo1cjq/ChUqlEpd5cuXd3husVhks9lKZd4AAOc44gQAuGQPP/yw9u/fr3feeUe//fab4uPjC/X5+eef7f8+f/68NmzYoPr160uSmjVrpu3btysyMlK1a9d2ePj4+DhdZv369bVq1SqHtlWrVqlOnTry9PQslfVq1qyZ0tLSVK5cuUJ1BQUFSZLy8vL08MMPq3fv3ho7dqwGDBhQ5NGfSpUqKTIyssjhyevXr6+DBw/q4MGD9rbffvtNJ0+eVIMGDUplnQAAF4fgBAC4ZIGBgbr//vv1/PPP684771SNGjUK9Zk8ebK++OIL/f777xo0aJD+/PNP9e/fX5I0aNAgnThxQn379tUvv/yi1NRULV26VAkJCUWedjd06FClpKRo7Nix2rVrl2bMmKFJkybpueeec7n+/Px8bd682eGxY8cOxcbGKiYmRt26ddN3332nffv2afXq1Ro2bJjWr18vSRo2bJiysrL0zjvv6MUXX1SdOnXs6+XMqFGjNGHCBL3zzjvavXu3Nm7cqHfffVeSFBsbq0aNGumhhx7Sxo0btW7dOsXFxal9+/Zq0aKFy+sFACg9BCcAQKl49NFHlZeXV2RoeO211/Taa6+pcePGWrlypRYvXmw/alOtWjWtWrVK+fn5uvPOO9WoUSM988wzCggIkIeH811Vs2bN9Nlnn2nu3Llq2LChRowYoTFjxqhfv34u13769Gk1bdrU4dGlSxdZLBZ98803ateunRISElSnTh316dNH+/fvV0hIiJYvX66JEydq5syZ8vPzk4eHh2bOnKkVK1bo/fffd7qs+Ph4TZw4Ue+9955uuukm3Xvvvdq9e7ekC6fcffnllwoMDFS7du0UGxurWrVqad68eS6vEwCgdFkMwzDcXQQA4Oo3c+ZMPfvsszpy5Ii8vLzs7fv27VPNmjW1adOmQvczAgDgasHgEACAS3LmzBkdPXpUr732mh5//HGH0AQAwLWCU/UAAJfk9ddfV7169RQaGqqkpCR3lwMAwGXBqXoAAAAAYIIjTgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACb+H+Xi4Cx6+0FEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# creating the dataset\n",
        "data = {'S':token_accuracy, 'S_weighted':magnitude_accuracy}\n",
        "types = list(data.keys())\n",
        "accuracies = list(data.values())\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# creating the bar plot\n",
        "plt.bar(types, accuracies, color ='blue',\n",
        "        width = 0.4)\n",
        "\n",
        "plt.xlabel(\"Type of Lexicon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy for different type of classification using Lexicon\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNhS8OCVxMHd"
      },
      "source": [
        "#### (Q1.4) A better threshold (1pt)\n",
        "Above we have defined a threshold to account for an inherent bias in the dataset: there are more positive than negative words per review.\n",
        "However, that threshold does not take into account *document length*. Explain why this is a problem and implement an alternative way to compute the threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxv_z62PvGQZ"
      },
      "source": [
        "The threshold for classifying document sentiment is initially set at 8. However, this threshold is subject to adjustment based on the document's length. The underlying logic is that for longer documents, the threshold is increased because a greater length may indicate the presence of more positive words, making the sentiment classification more context-aware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwt0B8h8aKjr",
        "outputId": "dfc2a8d3-b596-4f89-ca03-a444499955a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6890\n"
          ]
        }
      ],
      "source": [
        "# The idea is the following, we first calculate the average length of reviews.\n",
        "# Then for each review we take the it's length and use it as a ratio (so if the length is longer we increase the amount of positives required)\n",
        "lexicon = make_lexicon(weighted=False)\n",
        "\n",
        "results = []\n",
        "average_len_doc = sum(len(build_document(review).split()) for review in reviews) / len(reviews) # Get the average length of document\n",
        "\n",
        "for review in reviews:\n",
        "  document = build_document(review) # Combine all the sub-reviews together in a string\n",
        "\n",
        "  true_sentiment = review[\"sentiment\"] # Get true sentiment\n",
        "  predict_sentiment = classify_review(document, lexicon, weighted=False, threshold=9 * len(document)/average_len_doc)  # Make a prediciton\n",
        "\n",
        "  results.append(1 if true_sentiment == predict_sentiment else 0) # If prediction is correct add 1\n",
        "\n",
        "results = sum(results)/len(results)\n",
        "print(\"Accuracy: %0.4f\" % magnitude_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibV4nR89BXb"
      },
      "source": [
        "# (2) Naive Bayes (9.5pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnF9adQnuwia"
      },
      "source": [
        "\n",
        "Your second task is to program a simple Machine Learning approach that operates\n",
        "on a simple Bag-of-Words (BoW) representation of the text data, as\n",
        "described by Pang et al. (2002). In this approach, the only features we\n",
        "will consider are the words in the text themselves, without bringing in\n",
        "external sources of information. The BoW model is a popular way of\n",
        "representing texts as vectors, making it\n",
        "easy to apply classical Machine Learning algorithms on NLP tasks.\n",
        "However, the BoW representation is also very crude, since it discards\n",
        "all information related to word order and grammatical structure in the\n",
        "original text—as the name suggests.\n",
        "\n",
        "## Writing your own classifier (4pts)\n",
        "\n",
        "Write your own code to implement the Naive Bayes (NB) classifier. As\n",
        "a reminder, the Naive Bayes classifier works according to the following\n",
        "equation:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n",
        "where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n",
        "$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n",
        "vector. Remember that we use the log of these probabilities when making\n",
        "a prediction:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
        "\n",
        "You can find more details about Naive Bayes in [Jurafsky &\n",
        "Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n",
        "this helpful\n",
        "[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n",
        "\n",
        "*Note: this section and the next aim to put you in a position to replicate\n",
        "    Pang et al.'s Naive Bayes results. However, your numerical results\n",
        "    will differ from theirs, as they used different data.*\n",
        "\n",
        "**You must write the Naive Bayes training and prediction code from\n",
        "scratch.** You will not be given credit for using off-the-shelf Machine\n",
        "Learning libraries.\n",
        "\n",
        "The data contains the text of the reviews, where each document consists\n",
        "of the sentences in the review, the sentiment of the review and an index\n",
        "(cv) that you will later use for cross-validation. The\n",
        "text has already been tokenised and POS-tagged for you. Your algorithm\n",
        "should read in the text, **lowercase it**, store the words and their\n",
        "frequencies in an appropriate data structure that allows for easy\n",
        "computation of the probabilities used in the Naive Bayes algorithm, and\n",
        "then make predictions for new instances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEpyQSBSkb33"
      },
      "source": [
        "#### (Q2.1) Unseen words (1pt)\n",
        "The presence of words in the test dataset that\n",
        "have not been seen during training can cause probabilities in the Naive Bayes classifier to equal $0$.\n",
        "These can be words which are unseen in both positive and negative training reviews (case 1), but also words which are seen in reviews _of only one sentiment class_ in the training dataset (case 2). In both cases, **you should skip these words for both classes at test time**.  What would be the problem instead with skipping words only for one class in case 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BanFiYYnoxDW"
      },
      "source": [
        "The problem with skipping words only for one class (case 2) in the test dataset is that it can lead to biased and inaccurate classification results. Since the dataset is already imbalenced (as mentioned previosly), it is very probable that a word in in the positive class but not the negative one, therefore it is very likely that those words would also lead to a 0 probability.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZRhaI3WvzC"
      },
      "source": [
        "#### (Q2.2) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining (positive and negative) reviews cv900–cv999.  Report results using classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpiqGVWxdVV",
        "outputId": "59cd1bb5-c5c9-4ab9-90b9-ef3384f911eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.82\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k=1):\n",
        "        \"\"\"\n",
        "        Initialize a Naive Bayes Classifier with Laplace smoothing.\n",
        "\n",
        "        Parameters:\n",
        "        k (int): The Laplace smoothing constant (default is 1).\n",
        "\n",
        "        This class initializes a Naive Bayes Classifier with Laplace smoothing.\n",
        "        Laplace smoothing is used to avoid zero probabilities and provide more robust classification.\n",
        "        \"\"\"\n",
        "        self.doc_counter = Counter()\n",
        "        self.token_counter = {'POS': Counter(), 'NEG': Counter()}\n",
        "        self.total_tokens = {'POS': 0, 'NEG': 0}\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, reviews):\n",
        "        \"\"\"\n",
        "        Fit the Naive Bayes Classifier to a list of reviews.\n",
        "\n",
        "        Parameters:\n",
        "        reviews (list): A list of reviews, each containing 'sentiment' and 'content' information.\n",
        "\n",
        "        This method calculates and stores prior and conditional probabilities for the classifier based on the provided reviews.\n",
        "        \"\"\"\n",
        "\n",
        "        # Iterate over each review in the provided list of reviews.\n",
        "        for r in reviews:\n",
        "            sentiment = r['sentiment']  # Extract the sentiment label from the review.\n",
        "            self.doc_counter[sentiment] += 1  # Update the document count for the respective sentiment.\n",
        "\n",
        "            # Iterate over each sentence in the review's content.\n",
        "            for sentence in r['content']:\n",
        "                if len(sentence) == 0:\n",
        "                    continue  # Skip empty sentences.\n",
        "\n",
        "                # Iterate over each token data (word) in the sentence.\n",
        "                for token_data in sentence:\n",
        "                    tokens = [token.lower() for token in token_data]  # Convert tokens to lowercase.\n",
        "\n",
        "                    if len(tokens[:-1]) == 1:\n",
        "                        self.token_counter[sentiment][tokens[0]] += 1  # Count single tokens.\n",
        "                    else:\n",
        "                        self.token_counter[sentiment][tuple(tokens[:-1])] += 1  # Count n-grams (tuples).\n",
        "\n",
        "        # Calculate total token counts for both positive (POS) and negative (NEG) classes.\n",
        "        for c_class in [\"POS\", \"NEG\"]:\n",
        "            self.total_tokens[c_class] = sum(self.token_counter[c_class].values()) + len(self.token_counter[c_class]) * self.k\n",
        "\n",
        "\n",
        "    def predict(self, content):\n",
        "        \"\"\"\n",
        "        Predict the sentiment of content using the Naive Bayes Classifier.\n",
        "\n",
        "        Parameters:\n",
        "        content (list): A list of sentences, each containing tokens to be classified.\n",
        "\n",
        "        Returns:\n",
        "        str: The predicted sentiment label ('POS' for positive or 'NEG' for negative).\n",
        "\n",
        "        This method predicts the sentiment of content based on the trained Naive Bayes Classifier with Laplace smoothing.\n",
        "        It calculates posterior probabilities for both 'POS' and 'NEG' classes and assigns the label with the higher probability as the predicted sentiment.\n",
        "        \"\"\"\n",
        "        posterior = {}\n",
        "        for c_class in [\"POS\", \"NEG\"]:\n",
        "            p = self.doc_counter[c_class] / sum(self.doc_counter.values())\n",
        "            posterior[c_class] = np.log(p)  # Calculate the log-prior probability for the class.\n",
        "\n",
        "            for sentence in content:\n",
        "                if len(sentence) == 0:  # Skip if the sentence is empty.\n",
        "                    continue\n",
        "\n",
        "                for token_data in sentence:\n",
        "                    tokens = [token.lower() for token in token_data]\n",
        "\n",
        "                    if len(sentence[0]) == 2:\n",
        "                        final_tokens = tokens[0]\n",
        "                    else:\n",
        "                        final_tokens = tuple(tokens[:-1])  # Extract the tokens if n-grams.\n",
        "\n",
        "                    if all(final_tokens in value for value in self.token_counter.values()):  # Check if token is in both classes.\n",
        "                        token_prob = (self.token_counter[c_class][final_tokens] + self.k) / self.total_tokens[c_class]  # Calculate token probability.\n",
        "                        posterior[c_class] += np.log(token_prob)  # Update the log-posterior probability for the class.\n",
        "\n",
        "        return max(posterior, key=posterior.get)  # Return the class label with the highest log-posterior probability.\n",
        "\n",
        "NB_classifier = NaiveBayesClassifier(k=0)\n",
        "NB_classifier.fit(reviews[:900] + reviews[1000:1900])\n",
        "test_reviews = reviews[900:1000] + reviews[1900:]\n",
        "NB_results = [int(NB_classifier.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "NB_accuracy = sum(NB_results) / len(NB_results)\n",
        "print(f\"Naive Bayes accuracy: {NB_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0INK-PBoM6CB"
      },
      "source": [
        "#### (Q2.3) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n",
        "\n",
        "Simulate this scenario by keeping the positive reviews\n",
        "data unchanged, but only using negative reviews cv000–cv089 for\n",
        "training, and cv900–cv909 for testing. Calculate the classification\n",
        "accuracy, and explain what changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFbcsYlipBAw"
      },
      "source": [
        "In a situation where 90% of the data instances are positive movie reviews, accuracy alone may not be a suitable evaluation metric. This imbalance can lead to artificially high accuracy, making it misleading. As a classifier that only predicts \"Positive\" would get 0.9% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFLRQdtZZlxj",
        "outputId": "f9ff0b80-988e-4641-a78a-88299f135d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "NB_classifier = NaiveBayesClassifier(k=0)\n",
        "NB_classifier.fit(reviews[:90] + reviews[1000:1900])\n",
        "test_reviews = reviews[900:910] + reviews[1900:]\n",
        "NB_results = [int(NB_classifier.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "NB_accuracy = sum(NB_results) / len(NB_results)\n",
        "print(f\"Naive Bayes accuracy: {NB_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wJzcHX3WUDm"
      },
      "source": [
        "## Smoothing (1pt)\n",
        "\n",
        "As mentioned above, the presence of words in the test dataset that\n",
        "have not been seen during training can cause probabilities in the Naive\n",
        "Bayes classifier to be $0$, thus making that particular test instance\n",
        "undecidable. The standard way to mitigate this effect (as well as to\n",
        "give more clout to rare words) is to use smoothing, in which the\n",
        "probability fraction\n",
        "$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n",
        "$w_i$ becomes\n",
        "$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNIcbwUWphC"
      },
      "source": [
        "#### (Q2.4) Implement Laplace feature smoothing (1pt)\n",
        "Implement Laplace smoothing, i.e., smoothing with a constant value ($smoothing(w) = \\kappa, \\forall w \\in V$), in your Naive\n",
        "Bayes classifier’s code, and report the accuracy.\n",
        "Use $\\kappa = 1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTTD3cHper6X",
        "outputId": "8b03f56e-4a4a-4da1-d6ab-16eda5d35cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.83\n"
          ]
        }
      ],
      "source": [
        "NB_classifier = NaiveBayesClassifier(k=1)\n",
        "NB_classifier.fit(reviews[:900] + reviews[1000:1900])\n",
        "test_reviews = reviews[900:1000] + reviews[1900:]\n",
        "NB_results = [int(NB_classifier.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "NB_accuracy = sum(NB_results) / len(NB_results)\n",
        "print(f\"Naive Bayes accuracy: {NB_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGcgwba87D5"
      },
      "source": [
        "## Cross-Validation (1.5pts)\n",
        "\n",
        "A serious danger in using Machine Learning on small datasets, with many\n",
        "iterations of slightly different versions of the algorithms, is ending up with Type III errors, also called the “testing hypotheses\n",
        "suggested by the data” errors. This type of error occurs when we make\n",
        "repeated improvements to our classifiers by playing with features and\n",
        "their processing, but we don’t get a fresh, never-before seen test\n",
        "dataset every time. Thus, we risk developing a classifier that gets better\n",
        "and better on our data, but only gets worse at generalizing to new, unseen data. In other words, we risk developping a classifier that overfits.\n",
        "\n",
        "A simple method to guard against Type III errors is to use\n",
        "Cross-Validation. In **N-fold Cross-Validation**, we divide the data into N\n",
        "distinct chunks, or folds. Then, we repeat the experiment N times: each\n",
        "time holding out one of the folds for testing, training our classifier\n",
        "on the remaining N - 1 data folds, and reporting performance on the\n",
        "held-out fold. We can use different strategies for dividing the data:\n",
        "\n",
        "-   Consecutive splitting:\n",
        "  - cv000–cv099 = Split 1\n",
        "  - cv100–cv199 = Split 2\n",
        "  - etc.\n",
        "  \n",
        "-   Round-robin splitting (mod 10):\n",
        "  - cv000, cv010, cv020, … = Split 1\n",
        "  - cv001, cv011, cv021, … = Split 2\n",
        "  - etc.\n",
        "\n",
        "-   Random sampling/splitting\n",
        "  - Not used here (but you may choose to split this way in a non-educational situation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OeLcbSauGtR"
      },
      "source": [
        "#### (Q2.5) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q2.4 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KeCGPa7Nuzx",
        "outputId": "695e9aef-577b-4fdb-dd0d-3eb70a984615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracies: [0.775, 0.825, 0.81, 0.855, 0.765, 0.855, 0.825, 0.79, 0.82, 0.805] with average: 0.8125\n"
          ]
        }
      ],
      "source": [
        "k = 10  # Number of folds\n",
        "accuracies = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for i in range(k):\n",
        "    # Split data into training and test sets\n",
        "    train_reviews = [r for j, r in enumerate(reviews) if j % k != i]\n",
        "    test_reviews = [r for j, r in enumerate(reviews) if j % k == i]\n",
        "\n",
        "    NB = NaiveBayesClassifier()\n",
        "    NB.fit(train_reviews)\n",
        "\n",
        "    # Calculate accuracy for the test set\n",
        "    results = [int(NB.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "    accuracy = sum(results) / len(results)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(\"Overall accuracies:\", accuracies, \"with average:\", average_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otdlsDXBNyOa"
      },
      "source": [
        "#### (Q2.6) Report the variance of the 10 accuracy scores. (0.5pt)\n",
        "\n",
        "**Please report all future results using 10-fold cross-validation now\n",
        "(unless told to use the held-out test set).** Note: you're not allowed to use a library for computing the variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoBQm1KuNzNR",
        "outputId": "19d62c00-d36a-49b8-cbed-782add441119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0008212499999999988\n"
          ]
        }
      ],
      "source": [
        "print(sum((accuracies - average_accuracy)**2) / len(accuracies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6A2zX9_BRKm"
      },
      "source": [
        "## Features, overfitting, and the curse of dimensionality\n",
        "\n",
        "In the Bag-of-Words model, ideally we would like each distinct word in\n",
        "the text to be mapped to its own dimension in the output vector\n",
        "representation. However, real world text is messy, and we need to decide\n",
        "on what we consider to be a word. For example, is “`word`\" different\n",
        "from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n",
        "definition, and the number of features explodes, while our algorithm\n",
        "fails to learn anything generalisable. Too lax, and we risk destroying\n",
        "our learning signal. In the following section, you will learn about\n",
        "confronting the feature sparsity and the overfitting problems as they\n",
        "occur in NLP classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKK8FNt8VtcZ"
      },
      "source": [
        "### Stemming (1.5pts)\n",
        "\n",
        "To make your algorithm more robust, use stemming and hash different inflections of a word to the same feature in the BoW vector space. Please use the [Porter stemming\n",
        "    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3-2Z7_fJAz1"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import *\n",
        "import copy\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemsentence = copy.deepcopy(reviews)\n",
        "for i, review in enumerate(reviews):\n",
        "  for j, sentences in enumerate(review[\"content\"]):\n",
        "    for k, sentence in enumerate(sentences):\n",
        "      for l, words in enumerate(sentence):\n",
        "        stemsentence[i][\"content\"][j][k][l] = stemmer.stem(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SrJ1BeLXTnk"
      },
      "source": [
        "#### (Q2.7): How does the performance of your classifier change when you use stemming on your training and test datasets? (1pt)\n",
        "Use cross-validation to evaluate the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m4yfvTvJpx2",
        "outputId": "ea95e4bf-4d40-49de-9800-9e47cba52c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracies: [0.78, 0.83, 0.805, 0.86, 0.785, 0.85, 0.82, 0.78, 0.84, 0.81] with average: 0.8160000000000001\n"
          ]
        }
      ],
      "source": [
        "k = 10  # Number of folds\n",
        "accuracies = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for i in range(k):\n",
        "    # Split data into training and test sets\n",
        "    train_reviews = [r for j, r in enumerate(stemsentence) if j % k != i]\n",
        "    test_reviews = [r for j, r in enumerate(stemsentence) if j % k == i]\n",
        "\n",
        "    NB = NaiveBayesClassifier()\n",
        "    NB.fit(train_reviews)\n",
        "\n",
        "    # Calculate accuracy for the test set\n",
        "    results = [int(NB.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "    accuracy = sum(results) / len(results)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(\"Overall accuracies:\", accuracies, \"with average:\", average_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkDHVq_1XUVP"
      },
      "source": [
        "#### (Q2.8) What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q2.4)? (0.5pt)\n",
        "Give actual numbers. You can use the held-out training set to determine these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IAACNkf46jI"
      },
      "outputs": [],
      "source": [
        "def vocabulary_size(reviews):\n",
        "    \"\"\"\n",
        "    Calculate the vocabulary size of a list of reviews.\n",
        "\n",
        "    Parameters:\n",
        "    reviews (list): A list of reviews\n",
        "\n",
        "    Returns:\n",
        "    set: A set containing unique words from the reviews.\n",
        "\n",
        "    This function calculates the vocabulary size of a list of reviews by extracting unique words from the review content.\n",
        "    \"\"\"\n",
        "\n",
        "    set_words = set()  # Initialize an empty set to store unique words.\n",
        "\n",
        "    # Iterate over each review in the list.\n",
        "    for review in reviews:\n",
        "        # Iterate over each sentence in the review's content.\n",
        "        for sentences in review[\"content\"]:\n",
        "            # Iterate over each sentence in the sentences.\n",
        "            for sentence in sentences:\n",
        "                  if len(sentence[:-1])==1:\n",
        "                    set_words.add(sentence[0])  # Add the word to the set of unique words.\n",
        "                  else: # This is for a later question with the n-grams (in this scenario we want to compares the n-grams)\n",
        "                    set_words.add(tuple(sentence[:-1]))\n",
        "\n",
        "    return set_words  # Return the set of unique words, representing the vocabulary size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA3vee5-rJyy",
        "outputId": "c7206fe7-7544-4890-c07a-3a9a2c423986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the vocabulary without stemming: 55384\n",
            "Size of the vocabulary with stemming: 34200\n"
          ]
        }
      ],
      "source": [
        "set_words_1grams = vocabulary_size(reviews)\n",
        "print(\"Size of the vocabulary without stemming:\", len(set_words_1grams))\n",
        "\n",
        "set_words = vocabulary_size(stemsentence) # Using the stem vocabulary from Q.2.6\n",
        "print(\"Size of the vocabulary with stemming:\", len(set_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoazfxbNV5Lq"
      },
      "source": [
        "### N-grams (1.5pts)\n",
        "\n",
        "A simple way of retaining some of the word\n",
        "order information when using bag-of-words representations is to use **n-gram** features.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHjy3I7-qWiu"
      },
      "source": [
        "#### (Q2.9) Retrain your classifier from (Q2.4) using **unigrams+bigrams** and **unigrams+bigrams+trigrams** as features. (1pt)\n",
        "Report accuracy and compare it with that of the approaches you have previously implemented. You are allowed to use NLTK to build n-grams from sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6AGOVMI7hFa"
      },
      "outputs": [],
      "source": [
        "def make_ngrams(reviews, amount_ngrams):\n",
        "    \"\"\"\n",
        "    Create n-grams from the content of reviews.\n",
        "\n",
        "    Parameters:\n",
        "    reviews (list): A list of review dictionaries, where each dictionary contains content to create n-grams from.\n",
        "    amount_ngrams (int): The number of n-grams to generate.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of review dictionaries with n-grams added to their content.\n",
        "\n",
        "    This function takes a list of review dictionaries and generates n-grams from the content of each review's sentences.\n",
        "    It adds the n-grams to the content and returns a new list of review dictionaries with n-grams included.\n",
        "    \"\"\"\n",
        "\n",
        "    ngrams_list = copy.deepcopy(reviews)  # Create a deep copy of the original reviews list.\n",
        "\n",
        "    # Iterate over each review in the list.\n",
        "    for i, review in enumerate(reviews):\n",
        "        # Iterate over each sentence in the review's content.\n",
        "        for j, sentence in enumerate(review[\"content\"]):\n",
        "            joined_sent = full_sentence(sentence)  # Join the tokens in the sentence into a single string.\n",
        "\n",
        "            ngram = list(ngrams(joined_sent.split(), amount_ngrams))  # Generate n-grams from the sentence tokens.\n",
        "\n",
        "            # Use list comprehension to generate n-grams and append underscores (useless character to match adverb token).\n",
        "            ngrams_list[i][\"content\"][j] = [list(ngram_el) + [\"_\"] for ngram_el in ngram]\n",
        "\n",
        "    return ngrams_list  # Return the list of review dictionaries with n-grams added to their content.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DNDomUPlSbIc",
        "outputId": "faeba8b7-babd-431f-d16c-46c871e1189f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.82\n"
          ]
        }
      ],
      "source": [
        "bigrams = make_ngrams(reviews, amount_ngrams=2)\n",
        "\n",
        "NB_classifier = NaiveBayesClassifier(k=1)\n",
        "NB_classifier.fit(bigrams[:900] + reviews[:900] + bigrams[1000:1900] + reviews[1000:1900])\n",
        "test_reviews = reviews[900:1000] + reviews[1900:] + bigrams[900:1000] + bigrams[1900:]\n",
        "NB_results = [int(NB_classifier.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "NB_accuracy = sum(NB_results) / len(NB_results)\n",
        "print(f\"Naive Bayes accuracy: {NB_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eYuKMTOpq9jz",
        "outputId": "62923e70-fa2c-4497-e0e3-d77fa7bd2aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy: 0.80\n"
          ]
        }
      ],
      "source": [
        "trigrams = make_ngrams(reviews, amount_ngrams=3)\n",
        "\n",
        "NB_classifier = NaiveBayesClassifier(k=1)\n",
        "NB_classifier.fit(trigrams[:900]+ reviews[:900] + bigrams[:900] + reviews[1000:1900] + bigrams[1000:1900] + trigrams[1000:1900])\n",
        "test_reviews = reviews[900:1000] + reviews[1900:] + bigrams[900:1000] + bigrams[1900:] + trigrams[900:1000] + trigrams[1900:]\n",
        "NB_results = [int(NB_classifier.predict(r['content']) == r['sentiment']) for r in test_reviews]\n",
        "NB_accuracy = sum(NB_results) / len(NB_results)\n",
        "print(f\"Naive Bayes accuracy: {NB_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVrGGArkrWoL"
      },
      "source": [
        "\n",
        "#### Q2.10: How many features does the BoW model have to take into account now? (0.5pt)\n",
        "How would you expect the number of features to increase theoretically (e.g., linear, square, cubed, exponential)? How does this number compare, in practice, to the number of features at (Q2.8)?\n",
        "\n",
        "Use the held-out training set once again for this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEGZ9SV8pPaa"
      },
      "source": [
        "As the value of \"n\" in n-grams increases, the number of unique n-grams and features grows exponentially. This growth is a result of the increasing number of possible combinations of \"n\" consecutive words, which expands every time we move from n-grams to (n+1)-grams.\n",
        "\n",
        "In more precise terms, for a vocabulary size of \"V,\" the number of possible (n+1)-grams is determined by V*(n+1), and this growth follows an exponential pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_z8sAJeUrdtM",
        "outputId": "55ba3da0-350f-4f29-aa92-0646a8f2b598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the vocabulary for bigrams: 477485\n",
            "Size of the vocabulary for trigrams: 986354\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "set_words_bigrams = vocabulary_size(bigrams)\n",
        "print(\"Size of the vocabulary for bigrams:\", len(set_words_bigrams))\n",
        "\n",
        "set_words_trigrams = vocabulary_size(trigrams)\n",
        "print(\"Size of the vocabulary for trigrams:\", len(set_words_trigrams))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar([\"1-gram\", \"2-gram\", \"3-gram\"], [len(set_words_1grams), len(set_words_bigrams), len(set_words_trigrams)], width=0.5, color=\"blue\")\n",
        "\n",
        "for i, v in enumerate([len(set_words_1grams), len(set_words_bigrams), len(set_words_trigrams)]):\n",
        "  plt.text(i-0.1, v+ 5000, str(v))\n",
        "plt.ylabel(\"Amount of features\")\n",
        "plt.xlabel(\"N-grams\")\n",
        "plt.title(\"Number of features without stemming\")\n",
        "\n",
        "x= np.arange(3)\n",
        "y = [len(set_words_1grams), len(set_words_bigrams), len(set_words_trigrams)]\n",
        "p = np.polyfit(x, np.log(y), 1)\n",
        "plt.plot(x, np.exp(p[1]) * np.exp(p[0] * x), '--r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHWKDL3YV6vh"
      },
      "source": [
        "# (3) Support Vector Machines (4pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSYhcVaoJGt"
      },
      "source": [
        "Though simple to understand, implement, and debug, one\n",
        "major problem with the Naive Bayes classifier is that its performance\n",
        "deteriorates (becomes skewed) when it is being used with features which\n",
        "are not independent (i.e., are correlated). Another popular classifier\n",
        "that doesn’t scale as well to big data, and is not as simple to debug as\n",
        "Naive Bayes, but that doesn’t assume feature independence is the Support\n",
        "Vector Machine (SVM) classifier.\n",
        "\n",
        "You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n",
        "Other sources for learning SVM:\n",
        "* http://web.mit.edu/zoya/www/SVM.pdf\n",
        "* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n",
        "* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use the scikit-learn implementation of\n",
        "[SVM](http://scikit-learn.org/stable/modules/svm.html) with the default parameters. (You are not expected to perform any hyperparameter tuning, but feel free to do it if you think it gives you good insights for the discussion in question 5.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LnzNtQBV8gr"
      },
      "source": [
        "#### (Q3.1): Train SVM and compare to Naive Bayes (2pts)\n",
        "\n",
        "Train an SVM classifier (sklearn.svm.LinearSVC) using the features collected for Naive Bayes. Compare the\n",
        "classification performance of the SVM classifier to that of the Naive\n",
        "Bayes classifier with smoothing.\n",
        "Use cross-validation to evaluate the performance of the classifiers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JBscui8Mvoz0"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "\n",
        "#--------------------- HELPER FUNCTIONS ---------------------\n",
        "def create_folds(data, n_folds=10):\n",
        "    \"\"\"\n",
        "    Create folds using robin-round style.\n",
        "\n",
        "    Parameters:\n",
        "    data (list): Reviews containing the X_train and y_train.\n",
        "    n_folds (int): number of folds to split the data.\n",
        "\n",
        "    Returns:\n",
        "    folds (list): data splitted in n_folds.\n",
        "    \"\"\"\n",
        "    folds = []\n",
        "    fold_indices = []\n",
        "    n_data = len(data)\n",
        "\n",
        "    # computes indices using Round Robbin fashion\n",
        "    '''\n",
        "    fold: 0\n",
        "    [0, 10, 20, 30, 40, 50, 60, 70, ..., 960, 970, 980, 990]\n",
        "    fold: 1\n",
        "    [1, 11, 21, 31, 41, 51, 61, 71, ..., 961, 971, 981, 991]\n",
        "    fold: 2\n",
        "    [2, 12, 22, 32, 42, 52, 62, 72, ..., 962, 972, 982, 992]\n",
        "    fold: 3\n",
        "    [3, 13, 23, 33, 43, 53, 63, 73, ..., 963, 973, 983, 993]\n",
        "    fold: 4\n",
        "    [4, 14, 24, 34, ...\n",
        "    '''\n",
        "    # create indices for folds\n",
        "    for n in range(n_folds):\n",
        "        fold_indices.append(list(range(n, n_data, n_folds)))\n",
        "\n",
        "    # fill folds w/ corresponding indices\n",
        "    for cur_fold_indices in fold_indices:\n",
        "        folds.append([data[i] for i in cur_fold_indices])\n",
        "\n",
        "    return folds\n",
        "\n",
        "def split_data(cur_fold, folds):\n",
        "    \"\"\"\n",
        "    Extract from folds the training and testing data for current fold.\n",
        "\n",
        "    Parameters:\n",
        "    cur_fold (int): current fold number.\n",
        "    folds (list): data splitted in n_folds.\n",
        "\n",
        "    Returns:\n",
        "    lists: 1 out 10 folds for testing, remaining for training\n",
        "          - X_train : token + tag\n",
        "          - X_test  : token + tag\n",
        "          - y_train : 'NEG', 'POS'\n",
        "          - y_test  : 'NEG', 'POS'\n",
        "    \"\"\"\n",
        "    # get train & test data for current fold\n",
        "    train, test = [], []\n",
        "    for j, fold in enumerate(folds):\n",
        "      if j == cur_fold:\n",
        "          test.extend(fold)\n",
        "      else:\n",
        "          train.extend(fold)\n",
        "\n",
        "    # extract content and sentiment from reviews\n",
        "    X_train = [review['content'] for review in train]\n",
        "    y_train = [review['sentiment'] for review in train]\n",
        "\n",
        "    X_test = [review['content'] for review in test]\n",
        "    y_test = [review['sentiment'] for review in test]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def get_features(X_fold, pos_tags=False, closed_classes=False):\n",
        "    \"\"\"\n",
        "    Extract features accroding to methods ( POST Tagging, Closed-classes or None) from data.\n",
        "\n",
        "    Parameters:\n",
        "    X_fold (list): training data containing the word and tag.\n",
        "    pos_tags (bool): adds the tag to the features.\n",
        "    closed_classes (bool): keep data only nouns, verbs, adjectives, and adverbs.\n",
        "\n",
        "    Returns:\n",
        "    list: reviews presented as sentences w/ lowered words + tag (if applicable)\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    for i, review in enumerate(X_fold):\n",
        "      acc_sentences = \"\"\n",
        "      for sentence in review:\n",
        "        if len(sentence)==1:\n",
        "          continue\n",
        "\n",
        "        for word, tag in sentence:\n",
        "          word = word.lower()\n",
        "\n",
        "          # just add the word\n",
        "          if not (pos_tags or closed_classes):\n",
        "            acc_sentences += word + \" \"\n",
        "\n",
        "          # adding tag\n",
        "          if pos_tags:\n",
        "            acc_sentences += word + \"_\" + tag + \" \"\n",
        "\n",
        "          # keep only nouns, verbs, adjectives, and adverbs\n",
        "          if closed_classes:\n",
        "            if (tag.startswith('NN') or tag.startswith('VB') or\n",
        "                tag.startswith('JJ') or tag.startswith('RB')):\n",
        "              acc_sentences += word + \"_\" + tag + \" \"\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "      text.append(acc_sentences)\n",
        "    return text\n",
        "\n",
        "\n",
        "def train_SVM(clf, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Trains a SVM model classifier.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (list): training data with sentences having lowered-words (+ tag).\n",
        "    y_train (list): labels POS or NEG.\n",
        "\n",
        "    Returns:\n",
        "    object: model trained\n",
        "    \"\"\"\n",
        "    # train model\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "def get_acc(y_preds, y_test):\n",
        "    \"\"\"\n",
        "    Calcualted accuracies for current fold, compares truth to predicted labesl.\n",
        "\n",
        "    Parameters:\n",
        "    y_preds (list): predicted labels.\n",
        "    y_test  (list): truth labels POS or NEG.\n",
        "\n",
        "    Returns:\n",
        "    float: number indicating the accuracy of the model\n",
        "    \"\"\"\n",
        "    acc = 0.0\n",
        "    for i, y_pred in enumerate(y_preds):\n",
        "      # if same label increase accumulator\n",
        "      if y_pred == y_test[i]:\n",
        "        acc += 1\n",
        "    return (acc/len(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ZoZb9i3pxua"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.svm import LinearSVC\n",
        "def cros_val_SVM(reviews, n_folds=10, pos_tags=False, closed_class=False, print_fold_acc=False):\n",
        "  \"\"\"\n",
        "  Do cross validation w/ SVM as classifier on reviews data.\n",
        "\n",
        "  Parameters:\n",
        "  reviews (list): Reviews containing the X_train and y_train.\n",
        "  n_folds (int): number of folds.\n",
        "  pos_tags (bool): adds the tag to the features.\n",
        "  closed_classes (bool): keep data only nouns, verbs, adjectives, and adverbs.\n",
        "  print_fold_acc (bool): print per each fold the model accuracy\n",
        "\n",
        "  Returns:\n",
        "  float: number indicating the mean accuracy of the model\n",
        "  \"\"\"\n",
        "\n",
        "  # convert text to numerical features for SVM\n",
        "  # https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "  # Create 10 folds\n",
        "  folds = create_folds(reviews, n_folds=n_folds)\n",
        "  n_folds = len(folds)\n",
        "\n",
        "  # mean accuracy of the model\n",
        "  mean_accuracy = 0.0\n",
        "\n",
        "  # creates SVM clasifier\n",
        "  clf = LinearSVC()\n",
        "\n",
        "  # Train and eval each fold\n",
        "  print(f'--- Starting SVM Cross Validation ---')\n",
        "  if pos_tags:\n",
        "    print(\"-- Using: POST-Tagging\")\n",
        "  if closed_class:\n",
        "    print(\"-- Using: closed_class\")\n",
        "\n",
        "  for cur_fold in range(n_folds):\n",
        "    # split the data for training and evaluation\n",
        "    '''\n",
        "    X_train[0], X_train[1]\n",
        "    len(X_train[0]): 11 sentences -> [[['Damn', 'JJ'], ['that', 'IN'],..]\n",
        "    len(X_train[1]): 26 sentences -> [[['Janeane', 'NNP'], ['Garofalo', 'NNP'],..]\n",
        "\n",
        "    y_train\n",
        "    ['NEG', 'NEG', 'NEG', 'NEG', 'NEG', 'NEG', 'NEG'...\n",
        "    '''\n",
        "    X_train, y_train, X_test, y_test = split_data(cur_fold, folds)\n",
        "\n",
        "    # Q 3.2 & 3.3\n",
        "    X_train = get_features(X_train, pos_tags, closed_class)\n",
        "    X_test = get_features(X_test, pos_tags, closed_class)\n",
        "\n",
        "    # vectorize X data for SVM\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # train classifier w/ current folds\n",
        "    SVM_clf = train_SVM(clf, X_train_vec, y_train)\n",
        "\n",
        "    # predict labels\n",
        "    y_pred = SVM_clf.predict(X_test_vec)\n",
        "\n",
        "    # calcualte acc per fold\n",
        "    accuracy = get_acc(y_pred, y_test)\n",
        "    if print_fold_acc:\n",
        "      print(f\"Accuracy of {cur_fold}-fold : {accuracy}\")\n",
        "    mean_accuracy += accuracy\n",
        "\n",
        "  return mean_accuracy/n_folds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TwRuY7Hyp0L2",
        "outputId": "df49f11a-a0b4-415e-eadf-ff791d25b13e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting SVM Cross Validation ---\n",
            "Mean Accuracy: 0.8535\n"
          ]
        }
      ],
      "source": [
        "mean_accuracy = cros_val_SVM(reviews, n_folds=10, print_fold_acc=False)\n",
        "print(f\"Mean Accuracy: {mean_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636RqGiAp7IO"
      },
      "source": [
        "Comparison between 10_Cross-validation mean accuracacy results:\n",
        "  - NB w/ smoothing (k=1): 0.8125\n",
        "  - LinearSVM (only word): 0.8535"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifXVWcK0V9qY"
      },
      "source": [
        "### POS disambiguation (2pts)\n",
        "\n",
        "Now add in part-of-speech features. You will find the\n",
        "movie review dataset has already been POS-tagged for you ([here](https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf) you find the tagset). Try to\n",
        "replicate the results obtained by Pang et al. (2002).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA3I82o4oWGu"
      },
      "source": [
        "####(Q3.2) Replace your features with word+POS features, and report performance with the SVM. Use cross-validation to evaluate the classifier and compare the results with (Q3.1). Does part-of-speech information help? Explain why this may be the case. (1pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NOvjYe-t2Br6",
        "outputId": "6d7176ce-620e-4e4e-ed15-c19d46d211b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting SVM Cross Validation ---\n",
            "-- Using: POST-Tagging\n",
            "Mean Accuracy: 0.8559999999999999\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "mean_accuracy = cros_val_SVM(reviews, n_folds=10, pos_tags=True, print_fold_acc=False)\n",
        "print(f\"Mean Accuracy: {mean_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0dt_oQupUNe"
      },
      "source": [
        "*Write your answer here.*\n",
        "\n",
        "Comparison between 10_Cross-validation mean accuracacy results:\n",
        "  - NB w/ smoothing (k=1): 0.8125\n",
        "  - LinearSVM (only word): 0.8535\n",
        "  - LinearSVM (word + tag): 0.8559\n",
        "\n",
        "The difference in improvement is not significant which suggest that adding POS tag does not lead to major improvements on the performance of the SVM model at clasifying reviews. A reason for this could be due to the ambuigity when tagging the word. For instance when examining the reviews we see that one review has that `['drink', 'NN']` which without context this could be a verb or a noun, here set as a noun. Another example found in our data which (Beatrice, 1990) also mentions in her paper is the word one `['one', 'CD']` which could be expressed as cardinal number or as a noun. Therefore, the presense of these ambiguities when tagging words in different contexts does not lead to significant improvements when classifing the reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su-3w87eMW0w"
      },
      "source": [
        "#### (Q3.3) Discard all closed-class words from your data (keep only nouns, verbs, adjectives, and adverbs), and report performance. Does this help? Use cross-validation to evaluate the classifier and compare the results with (Q3.2). Are closed-class words detrimental to the classifier? Explain why this may be the case. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCUPlPozCYUX",
        "outputId": "61605da0-df9a-43c0-835c-902423e19f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting SVM Cross Validation ---\n",
            "-- Using: closed_class\n",
            "Mean Accuracy: 0.8629999999999999\n"
          ]
        }
      ],
      "source": [
        "# (tag.startswith('NN') or tag.startswith('VB') or tag.startswith('JJ') or tag.startswith('RB'))\n",
        "# NNP is also a noun, NNS is also a noun ... --> hence we use startswith\n",
        "mean_accuracy = cros_val_SVM(reviews, n_folds=10, closed_class=True, print_fold_acc=False)\n",
        "print(f\"Mean Accuracy: {mean_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaxCVrs8pWSp"
      },
      "source": [
        "*Write your answer here.*\n",
        "\n",
        "Comparison between 10_Cross-validation mean accuracacy results:\n",
        "  - NB w/ smoothing (k=1): 0.8125\n",
        "  - LinearSVM (only word): 0.8535\n",
        "  - LinearSVM (word + tag): 0.8559\n",
        "  - LinearSVM (word + open_class_tags): 0.8629\n",
        "\n",
        "We see a slighly improvement as compared to previous methods. In this case, we are only conserving nouns, verbs, adjectives, and adverbs (and all its variations i.e NNP, NNS and so on) which may encompass better the sentiment of a review. Thus, conserving the open classes makes for the slight improvement which prove not to be detrimental in this context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfwqOciAl2No"
      },
      "source": [
        "# (4) Discussion (max. 500 words). (5pts)\n",
        "\n",
        "> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n",
        "Why is this important? What are the limitations of these features and techniques?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYuse5WLmekZ"
      },
      "source": [
        "*Write your answer here in up to 500 words (-0.25pt for >50 extra words, -0.5 points for >100 extra words, ...)*.\n",
        "\n",
        "## Sentiment Lexicon\n",
        "**Results:**\n",
        "  - Sing: 0.679\n",
        "  - Weights: 0.689\n",
        "  - New Treshold without weights: 0.689\n",
        "\n",
        "**Sumary:**\n",
        "- Ignores the context of the word\n",
        "- Not explicit way how to model strong vs weak words. A weight of 2 was chosen. When increasing this factor accuracy suffered.\n",
        "- The updated threshold, when applied in conjunction with weights, does not yield substantial improvements. However, when utilized without incorporating weights, it leads to significant progress primarily attributed to the length adaptation.\n",
        "- Unbalanced data can be accounted by using a different treshold value. Those methods ara data dependent.\n",
        "\n",
        "## Naive Bayes\n",
        "**Results:**\n",
        "  - Vanilla: 0.82\n",
        "  - 90% Unbalanced: 0.60\n",
        "  - Smoothing: 0.812\n",
        "  - Steeming: 0.816\n",
        "  - Bigrams: 0.82\n",
        "  - Trigrams: 0.80\n",
        "\n",
        "**Sumary:**\n",
        "- Words are treated independently. This means their position in a sentence is not taken into account. For unigrams this is not ideal as negation of adjectives clearly change the sentiment of the review. For bigrams and above this was benefitial\n",
        "-In the case of imbalanced data, Vanilla Naive Bayes faces performance challenges as the model is predominantly exposed to one class. This lack of exposure to the minority class hinders the model's ability to adapt effectively, impacting its performance on the underrepresented class.\n",
        "- To avoid features not seen in the dataset smoothing can remediate probabilities being zero\n",
        "- Stemming helped with reduction of features while conserving `stem` information and slighly improving NB classifier.\n",
        "- Bi and Trigrams features can encompases context information.\n",
        "- Trigrams do not seem to improve our model. This could be due to adding unnecesary information which makes the classification of the review harder.\n",
        "\n",
        "## LinearSVM\n",
        "**Results:**\n",
        "  - LinearSVM (only word): 0.853\n",
        "  - LinearSVM (word + tag): 0.855\n",
        "  - LinearSVM (word + open_class_tags): 0.862\n",
        "\n",
        "**Sumary:**\n",
        "- Better performance than NB w/ smoothing as compared to vanilla LinearSVM and improvements with tag methods\n",
        "- Using POS_tagging improves our model as we are now introducing the lexical category (nouns, verbs, adjective, ..) of a word which in turn aids to the model to capture the sentiment of a review. For instance: finding happy_adj in a sentence are a direct clue for a POS sentiment.      \n",
        "- Encounter problem of ambuigity when tagging words without taking into account its context, i.e `drink` as verb or as a noun.\n",
        "- Open-classes can reduce the number of features while allowing for a slighlty improvement on accuracy as compared to POS_tagging (all tags). This is because closed-classes do not (generally) carry POS or NEG clues therefore by skipping these words we can save in memory thus reducing the number of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwaKwfWQhRk_"
      },
      "source": [
        "# Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOUeaET5ijk-"
      },
      "outputs": [],
      "source": [
        "# Write your names and student numbers here:\n",
        "# Student 1 #12345\n",
        "# Danilo Toapanta #14077566\n",
        "# Jort Vincenti #15209997"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A9K-H6Tii3X"
      },
      "source": [
        "**That's it!**\n",
        "\n",
        "- Check if you answered all questions fully and correctly.\n",
        "- Download your completed notebook using `File -> Download .ipynb`\n",
        "- Check if your answers are all included in the file you submit.\n",
        "- Submit your .ipynb file via *Canvas*. One submission per group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHslatYAKBrF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}